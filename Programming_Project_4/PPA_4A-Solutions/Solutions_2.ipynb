{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment - 4 B Solution\n",
    "\n",
    "## 4 A\n",
    "\n",
    "Use the MLLib API of Spark to construct a decision tree for the Breast Cancer Diagnostic data (Data-Link1) (we call it dataset1), available from the UC-Irvine ML repository. Select appropriate parameters to generate only a 3-level deep decision tree. Submit the following.\n",
    "\n",
    "a.\tYour program code.\n",
    "\n",
    "b.\tThe choice of parameters and attribute selection metric (Gini index, info gain, etc.) used.\n",
    "\n",
    "c.\tAny assumptions made.\n",
    "\n",
    "d.\tValidation and Train/Test Strategy used.\n",
    "\n",
    "e.\tDecision tree Obtained.\n",
    "\n",
    "f.\tPerformance shown by the confusion matrix.\n",
    "\n",
    "## 4 B\n",
    "\n",
    "Now use your own code to build a decision tree in Spark. Model your algorithm based on the homework assignment you did for designing the decision tree learning algorithm. Use excactly the same parameter choices as used in (1.) above. \n",
    "\n",
    "a.\tSubmit the same items (1.a-1.f) as for the question above.\n",
    "\n",
    "b.\tReproduce the results from the 1.e an d 1.f from the previous question and compare with the outputs obtained by your algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "b. The choice of parameters:\n",
    "\n",
    "    Max_depth = 3\n",
    "    \n",
    "    Attribute selection metric = Gini Index\n",
    "    \n",
    "    \n",
    "c. Any Assumptions made:\n",
    "\n",
    "    1. Must use only spark rdd's\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "d. Validation: \n",
    "\n",
    "Initially the data is randomly split into test and train. The data is trained on this train dataset to obtain the tree, which is then used to predicted on the test data.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Break down of the code:\n",
    "\n",
    "The entire code is broke down into following stages:\n",
    "\n",
    "    1. Find the min and max of each attribute using get_min_max() function.\n",
    "    \n",
    "    2. Create the bin width based on the min and max values as well as the number of bins desired using get_bin_width() function.\n",
    "    \n",
    "    3. Get the number of classes in the data and create a dictionary like {'B':0, 'M':1}. This dictionary maps each label to a number using get_labels() function.\n",
    "    \n",
    "    4. Clean the data: which removes the ID column and adds the 0 for class 'B' and 1 for class 'M'. Furthermore, it will transform the real valued features into bins using clean_data() function. \n",
    "    \n",
    "    5. Fill the table similar to the one shown in the fig 1 using get_num_rec() function.\n",
    "    \n",
    "    6. Get Info gain of each and every attribute and bin at test into a numpy array using get_Infogain_ar() function.\n",
    "    \n",
    "    7. In the get_tree() call all the above function in the same sequence until it reaches the 3rd level. \n",
    "    \n",
    "        7a. After getting Info gain numpy array. Find the one which has maximum and make it as a decision feature and corresponding bin*bin_width as the value based on the which it will proceed to the next node. \n",
    "        \n",
    "        7b. Store this information in the tree_dic dictionary as [Node : (feature, bin*bin_width, None, None)\n",
    "        \n",
    "        7c. Store the nodes impurities a.k.a the number of recs per class on the left and right child from the table obatined from the get_num_rec() function as numpy array of shape (features, bins, 2, # of classes).  \n",
    "        \n",
    "        7d. Split the rdd into two rdd's: \n",
    "            \n",
    "            l_rdd - this is the rdd which contains all the rows that contain value of the feature selected above <= bin*bin_width.\n",
    "            \n",
    "            r_rdd - this is the rdd which contains all the rows that contain value of the feature selected above > bin*bin_width.\n",
    "            \n",
    "        7e. Save the above two rdds which will be given to get_num_rec() function in the next iteration to get the similar table as we got above. These rdd's are stored in the dictionary nodes_rdd[2*i+1: l_rdd, 2*i+2: r_rdd]\n",
    "        \n",
    "        7f. Repeat the 7a - 7e until you get the tree of desired depth.\n",
    "    \n",
    "    8. Use interpret_tree() function to transform the obtained tree_dic and nodes_rec_frac to interpretable decision tree.\n",
    "    \n",
    "    9. Use predict() to predict the test data.\n",
    "    \n",
    "    10. Use confusion_mat() to get the confusion matrix.\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Data into an rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['842302,M,17.99,10.38,122.8,1001,0.1184,0.2776,0.3001,0.1471,0.2419,0.07871,1.095,0.9053,8.589,153.4,0.006399,0.04904,0.05373,0.01587,0.03003,0.006193,25.38,17.33,184.6,2019,0.1622,0.6656,0.7119,0.2654,0.4601,0.1189']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data into an rdd\n",
    "\n",
    "raw_rdd = sc.textFile(\"wdbc.csv\")\n",
    "\n",
    "raw_rdd.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step -1: Getting max and min of all the columns\n",
    "\n",
    "The following function will return the column number and its max as well as min value for that column.\n",
    "\n",
    "Inputs:\n",
    "\n",
    "    g_rdd - train data rdd\n",
    "    \n",
    "    f_col - number of irrelevant columns like class column and the ID column\n",
    "    \n",
    "    k - length of f_col\n",
    "    \n",
    "Outputs:\n",
    "\n",
    "    min_f - a dictionary where the feature number is key and min value is the value.\n",
    "    \n",
    "    max_f - a dictionary where the feature number is key and min value is the value.\n",
    "    \n",
    "    Example output:\n",
    "    \n",
    "        min_f - {0:2.5} \n",
    "        \n",
    "        max_f - {0:5.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get Max and Min for each column:\n",
    "\n",
    "# finding Max and Min of each feature using rdd:\n",
    "def get_min_max(g_rdd, f_col, k):\n",
    "    def min_max_mapper(x):\n",
    "    \n",
    "        x = x.split(\",\")\n",
    "        l_f_col = bc_f_col.value\n",
    "        l_k = bc_k.value\n",
    "        y = []\n",
    "        for i in range(0, len(x)):\n",
    "            if i in l_f_col:\n",
    "                continue\n",
    "            else:\n",
    "                y.append(str(i-k)+\"$\"+x[i])\n",
    "        return y\n",
    "\n",
    "    bc_k = sc.broadcast(k)\n",
    "\n",
    "    bc_f_col = sc.broadcast(f_col)\n",
    "\n",
    "    max_f_rdd = g_rdd.map(min_max_mapper)\\\n",
    "                       .flatMap(lambda x: x)\\\n",
    "                       .map(lambda x: (x.split(\"$\")[0],float(x.split(\"$\")[1])))\\\n",
    "                       .reduceByKey(max)\n",
    "\n",
    "\n",
    "    max_f = max_f_rdd.collect()\n",
    "    \n",
    "    max_fv = {}\n",
    "    \n",
    "    for i in range(0,len(max_f)):\n",
    "        max_fv[max_f[i][0]] = max_f[i][1]\n",
    "    \n",
    "    min_f_rdd = g_rdd.map(min_max_mapper)\\\n",
    "                   .flatMap(lambda x: x)\\\n",
    "                   .map(lambda x: (x.split(\"$\")[0],float(x.split(\"$\")[1])))\\\n",
    "                   .reduceByKey(min)\n",
    "\n",
    "    min_f = min_f_rdd.collect()\n",
    "    \n",
    "    min_fv = {}\n",
    "    \n",
    "    for i in range(0,len(max_f)):\n",
    "        min_fv[min_f[i][0]] = min_f[i][1]\n",
    "        \n",
    "        \n",
    "    return (min_fv,max_fv)\n",
    "\n",
    "# # Uncomment the following code to see what this function does\n",
    "# rem_col = [0]\n",
    "\n",
    "# label_col = [1]\n",
    "\n",
    "# f_col = rem_col + label_col\n",
    "\n",
    "# k = len(rem_col)+len(label_col)\n",
    "    \n",
    "# bins = 32\n",
    "\n",
    "# min_f, max_f = get_min_max(raw_rdd, f_col,k)\n",
    "\n",
    "# print(\"min_f:\",min_f)\n",
    "\n",
    "# print(\"max_f:\",max_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step -2 : Getting the bin width for each feature\n",
    "\n",
    "This function will return the bin_width for each feature.\n",
    "\n",
    "Inputs:\n",
    "\n",
    "    min_f - from get_min_max()\n",
    "    \n",
    "    max_f - from get_min_max()\n",
    "    \n",
    "    bins - number of bins \n",
    "    \n",
    "Outputs:\n",
    "\n",
    "    bin_width - a dictionary of bin width for each feature\n",
    "    \n",
    "    Example: {0:0.125}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the bin width\n",
    "\n",
    "# bins = 32\n",
    "\n",
    "def get_bin_width(min_f, max_f, bins):\n",
    "    \n",
    "    bin_width = {}\n",
    "\n",
    "    for i in range(0, len(max_f)):\n",
    "    \n",
    "        bin_width[str(i)]=(max_f[str(i)]-min_f[str(i)])/bins\n",
    "       \n",
    "    return bin_width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step - 3: Get the class labels in the dataset\n",
    "\n",
    "This function will make a dictionary of the class labels, where labels are key and a number is a value.\n",
    "\n",
    "Inputs:\n",
    "\n",
    "    g_rdd - the train data\n",
    "    \n",
    "    label_col - the label column\n",
    "    \n",
    "Outputs:\n",
    "\n",
    "    label_dic -  a dictionary where labels are key and a number is a value\n",
    "    \n",
    "    Example: {'B':0, 'M':1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(g_rdd, label_col):\n",
    "    bc_label_col = sc.broadcast(label_col)\n",
    "    \n",
    "    def get_labels_mapper(x):\n",
    "        x = x.split(\",\")\n",
    "        l_label_col = bc_label_col.value[0]\n",
    "        return str(x[l_label_col])\n",
    "    \n",
    "    labels_rdd = g_rdd.map(get_labels_mapper)\\\n",
    "                        .distinct()\n",
    "    labels = labels_rdd.collect()\n",
    "    \n",
    "    labels.sort()\n",
    "    \n",
    "    labels_dic = {}\n",
    "    \n",
    "    for i in range(0,len(labels)):\n",
    "        labels_dic[labels[i]] = i\n",
    "\n",
    "    return labels_dic\n",
    "\n",
    "# Uncomment the following to see what this function does\n",
    "# label_col = [1]\n",
    "\n",
    "# labels = get_labels(raw_rdd, label_col)\n",
    "\n",
    "# print(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step - 4: Getting the binned form of data \n",
    "\n",
    "This function will create a new cleaned rdd where each attribute value is replaced with the bin number. This bin number is chose in such a way that when you multiply it with the bin_width you get the upper limit of the bin in which it is present.\n",
    "\n",
    "For example:\n",
    "\n",
    "    attribute value = 5\n",
    "    \n",
    "    bin_width is 2\n",
    "    \n",
    "    bins :\n",
    "    \n",
    "    bin 1: 0-2\n",
    "    bin 2: 2-4\n",
    "    bin 3: 4-6\n",
    "    bin 4: 6-8\n",
    "    bin 5: 8-10\n",
    "    \n",
    "    Now 5 falls in bin number 3.\n",
    "    \n",
    "    When you multiply attribute value with bin number you get the upper limit of corresponding bin as follows:\n",
    "    \n",
    "        In this case it is : 3*2 = 6\n",
    "        \n",
    "    This information will be further used in the next steps to fill in the data for tabel in fig 1.\n",
    "    \n",
    "Inputs:\n",
    "\n",
    "    g_rdd - training data\n",
    "    \n",
    "    label_col - class column\n",
    "    \n",
    "    bin_width - dictionary obtained from the get_bin_width() function\n",
    "    \n",
    "    labels - dictionary obtained from the get_labels() function\n",
    "    \n",
    "    bins - number of bins\n",
    "    \n",
    "    min_f - min_f obtained from the get_min_max() function\n",
    "    \n",
    "Outputs:\n",
    "\n",
    "    clean_rdd - each attribute value is replaced with the bin number\n",
    "    \n",
    "    Example: [['0','0,2,1,32', '1,5,1,32', '2,7,1,32'...],['1','0,3,1,32', '1,6,1,32', '2,7,1,32']]\n",
    "    \n",
    "    first column : '0' => class\n",
    "    \n",
    "    second column: feature       => 0\n",
    "                   bin_number    => 2\n",
    "                   min_bin_number=> 1\n",
    "                   max_bin_number=> 32\n",
    "                   \n",
    "    Similar interpretation for all the other columns\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from math import ceil, floor\n",
    "\n",
    "def clean_data(g_rdd, rem_col, label_col, bin_width, labels, bins, min_f):\n",
    "    k = len(rem_col)+len(label_col)\n",
    "    bc_rem_col = sc.broadcast(rem_col)\n",
    "    bc_label_col = sc.broadcast(label_col)\n",
    "    bc_bin_width = sc.broadcast(bin_width)\n",
    "    bc_k = sc.broadcast(k)\n",
    "    bc_labels = sc.broadcast(labels)\n",
    "    bc_bins = sc.broadcast(bins)\n",
    "    bc_min_f = sc.broadcast(min_f)\n",
    "    \n",
    "    def clean_data_mapper(x):\n",
    "        \n",
    "        x = x.split(\",\")\n",
    "        l_rem_col = bc_rem_col.value\n",
    "        l_k = bc_k.value\n",
    "        l_bin_width = bc_bin_width.value\n",
    "        l_label_col = bc_label_col.value\n",
    "        l_labels = bc_labels.value\n",
    "        l_bins = bc_bins.value\n",
    "        l_min_f = bc_min_f.value\n",
    "        y = []\n",
    "        for i in range(0, len(x)):\n",
    "            if i in l_rem_col:\n",
    "                #y.append(x[i])\n",
    "                continue\n",
    "            elif i in l_label_col:\n",
    "                y.append(str(l_labels[x[i]]))\n",
    "            else:\n",
    "                z = (float(x[i])-l_min_f[str(i-l_k)])/l_bin_width[str(i-l_k)]\n",
    "                if floor(z)<z<ceil(z):\n",
    "                    z = ceil(z)\n",
    "                if z==0:\n",
    "                    z = 1\n",
    "                y.append(str(i-l_k)+\",\"+str(int(z))+\",\"+\"1\"+\",\"+str(l_bins))\n",
    "        return y\n",
    "\n",
    "    clean_rdd = g_rdd.map(clean_data_mapper)\n",
    "        \n",
    "    return clean_rdd\n",
    "\n",
    "# # Uncomment the following and run to see what this function does\n",
    "# rem_col = [0]\n",
    "\n",
    "# label_col = [1]\n",
    "\n",
    "# f_col = rem_col + label_col\n",
    "\n",
    "# k = len(rem_col)+len(label_col)\n",
    "    \n",
    "# bins = 32\n",
    "\n",
    "# min_f, max_f = get_min_max(f_col,k)\n",
    "    \n",
    "# bin_width = get_bin_width(min_f, max_f, bins)\n",
    "    \n",
    "# labels = get_labels(label_col)\n",
    "    \n",
    "# b=clean_data(raw_rdd, rem_col, label_col, bin_width, labels, bins, min_f)\n",
    "\n",
    "# b = b.filter(lambda x: x[2].split(\",\")[2]>\"32\")\n",
    "\n",
    "# print(min_f)\n",
    "\n",
    "# print(max_f)\n",
    "\n",
    "# print(bin_width)\n",
    "\n",
    "# print(b.first())\n",
    "\n",
    "# print(raw_rdd.first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step -5: Getting the numbers to fill the table like shown in the figure.\n",
    "\n",
    "The numbers are obatained using the logic discussed below:\n",
    "\n",
    "    In the Step -4 we got the rdd as shown below:\n",
    "    \n",
    "        [['0','0,2,1,32', '1,5,1,32', '2,7,1,32'...],['1','0,3,1,32', '1,6,1,32', '2,7,1,32']]\n",
    "        \n",
    "        Now each row in rdd is expanded as follows:\n",
    "        \n",
    "            ['0','0,2,1,32', '1,5,1,32', '2,7,1,32'...]\n",
    "            \n",
    "       =>   ('0', ['0,2,1,32', '1,5,1,32', '2,7,1,32'...])\n",
    "            \n",
    "       =>   ['0', '0,2,1,32'], ['0','1,5,1,32',], ['0','2,7,1,32']..\n",
    "            \n",
    "       =>   ('0,1,0,0',1), ('0,2,0,0',1), ('0,3,1,0',1), ('0,4,1,0',1)..\n",
    "            \n",
    "            In the above key - value pairs the key has the following four parts separated by \",\":\n",
    "            \n",
    "            ('0,1,0,0',1), ('0,2,0,0',1), ('0,3,1,0',1):\n",
    "            \n",
    "            for the current row, column '0' belongs to bin 2, so:\n",
    "                \n",
    "                It is greater than the upper limit of 1*bin_width => this is denoted by '0' at the third position. \n",
    "                \n",
    "                It is lesser than the upper limit of 3*bin_width => this is denoted byt '1' at the third poistion.\n",
    "                \n",
    "            The fourth position is the class label, in this case it is '0'.\n",
    "    \n",
    "    When we reduce by key and add we get enough information to fill the following table:\n",
    "    \n",
    "    Note: Assume in the place =< 55 it is the corresponding bin upper limit in our case.\n",
    "    \n",
    "<img src=\"Imp_fig.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we obtain the values, we will use 4 dimensional numpy array to visualize the above table.\n",
    "\n",
    "shape of numpy array: (features, bins, 2, class)\n",
    "\n",
    "2 denotes the =< and >\n",
    "\n",
    "Inputs:\n",
    "\n",
    "    g_rdd - an rdd/data at a node to determine the max info gain\n",
    "    \n",
    "    label_col - class label column\n",
    "    \n",
    "    bin - number of bins\n",
    "    \n",
    "    f_num - the number of features\n",
    "    \n",
    "    labels_num - number of classes\n",
    "    \n",
    "Output:\n",
    "\n",
    "    num_rec_ar - a 4-d numpy array realizing the above table of shape (features, bins, 2, class)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add\n",
    "import numpy as np\n",
    "\n",
    "def get_num_rec(g_rdd, label_col, bins, f_num, labels_num):\n",
    "    \n",
    "    b_label_col = sc.broadcast(label_col)\n",
    "    \n",
    "    def get_num_rec_mapper1(x):\n",
    "        z=[]\n",
    "        for i in range(0, len(x)):\n",
    "            if i!=0:\n",
    "                z.append(x[i])\n",
    "    \n",
    "        return(x[0],z)\n",
    "\n",
    "    def get_num_rec_mapper2(x):\n",
    "        \n",
    "        z = []\n",
    "        b = list(map(int,x[1].split(\",\")))\n",
    "        x_min = b[2]\n",
    "        x_max = b[3]\n",
    "        x_bin = b[1]\n",
    "        for i in range(x_min,x_max+1):\n",
    "            if x_bin<=i:\n",
    "                z.append((str(b[0])+\",\"+str(i)+\",\"+\"0\"+\",\"+x[0],1))\n",
    "            else:\n",
    "                z.append((str(b[0])+\",\"+str(i)+\",\"+\"1\"+\",\"+x[0],1))\n",
    "        return z\n",
    "\n",
    "    r_rdd = g_rdd.map(get_num_rec_mapper1)\\\n",
    "                       .flatMapValues(lambda x:x)\\\n",
    "                       .map(get_num_rec_mapper2)\\\n",
    "                       .flatMap(lambda x:x) \\\n",
    "                       .reduceByKey(add)\n",
    "                \n",
    "#    r_rdd = r_rdd.filter(lambda x: x[1][0].split(\",\")[1]==\"1\")\n",
    "    \n",
    "    r_rdd = r_rdd.sortByKey().collect()\n",
    "    num_rec_ar = np.zeros((f_num, bins, 2, labels_num))\n",
    "    \n",
    "    for k,v in r_rdd:\n",
    "        k = list(map(int,k.split(\",\")))\n",
    "        num_rec_ar[k[0]][(k[1]-1)][k[2]][k[3]] = v\n",
    "    \n",
    "    return num_rec_ar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step - 6: Compute the Info-gain array of each case\n",
    "\n",
    "Computation of each possible attribute and corresponding bin number Information gain is done by the following function.\n",
    "\n",
    "We will use Gini INdex to compute the Impurity of the node.\n",
    "\n",
    "Inputs:\n",
    "\n",
    "    num_rec_ar - a 4-d numpy array realizing the above table of shape (features, bins, 2, class)  obtained from get_num_rec\n",
    "    \n",
    "Outputs:\n",
    "\n",
    "    num_rec_frac - a numpy 4-d numpy array that sums up the accross the dimension 4 of the num_rec_ar \n",
    "    \n",
    "    current_node_imp - this a array that gives the number of records per class for the current node\n",
    "    \n",
    "    Infogain_ar - this array is the required infogain array to find the feature that has more Info-gain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_Infogain_ar(num_rec_ar):\n",
    "    \n",
    "    features, bins, dummy, labels = num_rec_ar.shape\n",
    "        \n",
    "    num_rec_ar_sum3 = np.sum(num_rec_ar, axis = 3, keepdims=True)\n",
    "        \n",
    "    num_rec_frac_ar = num_rec_ar/num_rec_ar_sum3\n",
    "    \n",
    "    num_rec_frac_ar[np.isnan(num_rec_frac_ar)] = 0\n",
    "    \n",
    "    # Gini Index\n",
    "\n",
    "    imp_ar = 1 - np.sum(num_rec_frac_ar**2,axis = 3, keepdims=True)\n",
    "    \n",
    "    ind = bins-1\n",
    "    \n",
    "    current_node_imp = imp_ar[0,ind,0,0]\n",
    "    \n",
    "    num_rec_ar_sum23 = np.sum(num_rec_ar_sum3, axis = 2,  keepdims=True)\n",
    "    \n",
    "    dum_np_ar = num_rec_ar_sum3[:,:-1,:,:]*imp_ar[:,:-1,:,:]/num_rec_ar_sum23[:,:-1,:,:]\n",
    "    \n",
    "    Infogain_ar = current_node_imp - np.sum(dum_np_ar, axis = 2)\n",
    "    \n",
    "    return num_rec_frac_ar, current_node_imp, Infogain_ar\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7-d: This will split the current node rdd into two child rdd's (left child and right child)\n",
    "\n",
    "This will split based on the feature and the bin number that is has been recognized to have the highest Info gain. \n",
    "\n",
    "The following modifications are important to the rdd after splitting:\n",
    "\n",
    "If the feature '0' and bin '5' has max Info gain then:\n",
    "\n",
    "        [['0','0,2,1,32', '1,5,1,32', '2,7,1,32'...],['1','0,3,1,32', '1,6,1,32', '2,7,1,32']]\n",
    "\n",
    "     => [['0','0,2,1,5', '1,5,1,32', '2,7,1,32'...],['1','0,3,1,5', '1,6,1,32', '2,7,1,32']]\n",
    "     \n",
    "     Max bin of feature '0' is change to 4+1='5'\n",
    "     \n",
    "If the feature '1' and the bin is '4' has max Info gain:\n",
    "\n",
    "        [['0','0,2,1,32', '1,5,1,32', '2,7,1,32'...]...]\n",
    "\n",
    "     => [['0','0,2,1,32', '1,5,5,32', '2,7,1,32'...]...]\n",
    "     \n",
    "     Min bin of the feature '1' is change to '5' \n",
    "\n",
    "Inputs:\n",
    "\n",
    "    g_rdd - rdd at that node\n",
    "    \n",
    "    rec_dec - recent decision made based on Max Info-gain, it is a tuple containing the (feature, bin number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_lr_rdd(g_rdd, rec_dec):\n",
    "    \n",
    "    bc_dec_f = sc.broadcast(rec_dec[0])\n",
    "    bc_dec_bin = sc.broadcast(rec_dec[1]+1)\n",
    "    \n",
    "    \n",
    "    def get_lr_rdd_mapper(x):\n",
    "        \n",
    "        l_dec_f = bc_dec_f.value\n",
    "        l_dec_bin = bc_dec_bin.value\n",
    "        \n",
    "        f_mod = list(map(int,x[l_dec_f+1].split(\",\")))\n",
    "        \n",
    "        if f_mod[1]<=l_dec_bin:\n",
    "            \n",
    "            f_mod[3]=l_dec_bin\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            f_mod[2]=l_dec_bin+1\n",
    "           \n",
    "        x[l_dec_f+1]=str(f_mod).replace(\"[\",\"\").replace(\"]\",\"\").replace(\" \",\"\")\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    def get_l_filter(x):\n",
    "        \n",
    "        l_dec_f = bc_dec_f.value\n",
    "        l_dec_bin = bc_dec_bin.value\n",
    "        \n",
    "        f_mod = list(map(int,x[l_dec_f+1].split(\",\")))\n",
    "        \n",
    "        if f_mod[1]<=l_dec_bin:\n",
    "            \n",
    "            return True \n",
    "            \n",
    "        else:\n",
    "            \n",
    "            return False\n",
    "    \n",
    "    def get_r_filter(x):\n",
    "        \n",
    "        return not get_l_filter(x)\n",
    "        \n",
    "    \n",
    "    l_rdd, r_rdd = (g_rdd.filter(f) for f in (get_l_filter, get_r_filter)) \n",
    "\n",
    "    l_rdd = l_rdd.map(get_lr_rdd_mapper)\n",
    "    \n",
    "    r_rdd = r_rdd.map(get_lr_rdd_mapper)\n",
    "    \n",
    "    return l_rdd, r_rdd\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step - 7: Generate the tree:\n",
    "\n",
    "What this function does?\n",
    "\n",
    "Call the functions from step-1 to step-6, then do:\n",
    "\n",
    "    7a. After getting Info gain numpy array. Find the one which has maximum and make it as a decision feature and corresponding bin*bin_width as the value based on the which it will proceed to the next node. \n",
    "\n",
    "    7b. Store this information in the tree_dic dictionary as [Node : (feature, bin*bin_width, None, None)\n",
    "\n",
    "    7c. Store the nodes impurities a.k.a the number of recs per class on the left and right child from the table obatined from the get_num_rec() function as numpy array of shape (features, bins, 2, # of classes).  \n",
    "\n",
    "    7d. Split the rdd into two rdd's: \n",
    "\n",
    "        l_rdd - this is the rdd which contains all the rows that contain value of the feature selected above <= bin*bin_width.\n",
    "\n",
    "        r_rdd - this is the rdd which contains all the rows that contain value of the feature selected above > bin*bin_width.\n",
    "\n",
    "    7e. Save the above two rdds which will be given to get_num_rec() function in the next iteration to get the similar table as we got above. These rdd's are stored in the dictionary nodes_rdd[2*i+1: l_rdd, 2*i+2: r_rdd]\n",
    "\n",
    "    7f. Repeat the 7a - 7e until you get the tree of desired depth.\n",
    "\n",
    "Inputs:\n",
    "\n",
    "    train_rdd - training data\n",
    "    \n",
    "    max_depth - depth of the tree\n",
    "    \n",
    "    total_col - total number of columns\n",
    "    \n",
    "    rem_col - columns that shouldn't be considered like ID column\n",
    "    \n",
    "    label_col - column in which class label is present\n",
    "    \n",
    "    bins - number of bins\n",
    "    \n",
    "Output:\n",
    "\n",
    "    tree_dic - decision tree in the form of an dictionary, where:\n",
    "                \n",
    "                {Node# : (feature_at_test, feature_value, None, None)}\n",
    "                \n",
    "    nodes_rec_frac - np_array obtained from the get_Infogain() function\n",
    "    \n",
    "    nodes_imp - number of records of each class at each node in the form of a dict as follows:\n",
    "    \n",
    "                {Node# : [records_of_class0, records_of_class1]}\n",
    "                \n",
    "    labels - labels dictionary of form :\n",
    "                \n",
    "                    {'B': 0, 'M': 1}\n",
    "                    \n",
    "    bin_width - bin width of each feature\n",
    "    \n",
    "    \n",
    "Tree is visualized as follows:\n",
    "\n",
    "    Node 0 : root node\n",
    "    \n",
    "    Node 1 : left child of root node\n",
    "    \n",
    "    Node 2 : right child of root node\n",
    "    \n",
    "    Node 3 : left child of (i-1)/2 here i=3 => parent is 2\n",
    "    \n",
    "    Node 4 : right child of (i-1)/2 here i=4 => parent is 2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_tree(train_rdd, max_depth, total_col, rem_col, label_col, bins):\n",
    "    \n",
    "    tree_dic = {}\n",
    "\n",
    "    nodes_rdd ={}\n",
    "    \n",
    "    nodes_imp = {}\n",
    "    \n",
    "    nodes_rec_frac = {}\n",
    "    \n",
    "    f_col = rem_col + label_col\n",
    "\n",
    "    k = len(rem_col)+len(label_col)\n",
    "    \n",
    "    f_num = total_col - k\n",
    "    \n",
    "    min_f, max_f = get_min_max(train_rdd, f_col, k)\n",
    "    \n",
    "    bin_width = get_bin_width(min_f, max_f, bins)\n",
    "    \n",
    "    labels = get_labels(train_rdd, label_col)\n",
    "    \n",
    "    clean_rdd = clean_data(train_rdd, rem_col, label_col, bin_width, labels, bins, min_f)\n",
    "     \n",
    "    nodes_rdd[0] = clean_rdd\n",
    "    \n",
    "    #i = 0\n",
    "    \n",
    "    #while max(tree_dic, key=tree_dic.get)==(2**(max_depth)-1):\n",
    "    \n",
    "    max_iter = (2**max_depth)-1\n",
    "\n",
    "    for i in range(0,max_iter): \n",
    "        \n",
    "        if i!=0 and 0 in nodes_rec_frac[i]:\n",
    "            \n",
    "            nodes_rec_frac[2*i+1] = nodes_rec_frac[i]\n",
    "            nodes_rec_frac[2*i+1] = nodes_rec_frac[i]\n",
    "            \n",
    "            nodes_rdd[2*i+1] = nodes_rdd[i]\n",
    "            nodes_rdd[2*i+2] = nodes_rdd[i]\n",
    "            \n",
    "            tree_dic[i] = None\n",
    "            \n",
    "            nodes_imp[i] = 0 \n",
    "            \n",
    "        else:    \n",
    "\n",
    "\n",
    "            num_rec_ar = get_num_rec(nodes_rdd[i], label_col, bins, f_num, len(labels))\n",
    "\n",
    "            num_rec_frac_ar, current_node_imp, Infogain_ar = get_Infogain_ar(num_rec_ar)\n",
    "\n",
    "        #     print(Infogain_ar.shape)\n",
    "\n",
    "        #     print(Infogain_ar[0])\n",
    "\n",
    "        #     print(current_node_imp)\n",
    "\n",
    "        #     print(num_rec_frac_ar.shape)\n",
    "\n",
    "        #     print(num_rec_frac_ar[0])\n",
    "\n",
    "        #     print(num_rec_ar[0])\n",
    "\n",
    "            dec_ind = np.where(Infogain_ar==np.nanmax(Infogain_ar))\n",
    "\n",
    "            dec_ind = list(a_i[0] for a_i in dec_ind)\n",
    "\n",
    "        #     print(dec_ind)\n",
    "\n",
    "            tree_dic[i] = (dec_ind[0], (dec_ind[1]+1)*bin_width[str(dec_ind[0])]+min_f[str(dec_ind[0])], None, None)\n",
    "\n",
    "            rec_t_dec = (dec_ind[0], dec_ind[1])\n",
    "\n",
    "            nodes_imp[i] = current_node_imp\n",
    "\n",
    "            if i==0:\n",
    "                nodes_rec_frac[i] = num_rec_ar[0,bins-1,0,:].astype(int).tolist()\n",
    "\n",
    "            nodes_rec_frac[2*i+1] = num_rec_ar[rec_t_dec[0], rec_t_dec[1],0,:].astype(int).tolist()\n",
    "\n",
    "            nodes_rec_frac[2*i+2] = num_rec_ar[rec_t_dec[0], rec_t_dec[1],1,:].astype(int).tolist()\n",
    "\n",
    "#             print(rec_t_dec)\n",
    "\n",
    "#             print(nodes_rec_frac)\n",
    "\n",
    "#             print(nodes_imp)\n",
    "\n",
    "    #        print(num_rec_ar[rec_t_dec[0],:,:,:])\n",
    "\n",
    "            l_rdd , r_rdd = get_lr_rdd(nodes_rdd[i], rec_t_dec)\n",
    "\n",
    "            nodes_rdd[2*i+1] = l_rdd\n",
    "\n",
    "            nodes_rdd[2*i+2] = r_rdd\n",
    "\n",
    "#             print(l_rdd.count())\n",
    "\n",
    "#             print(r_rdd.count())\n",
    "\n",
    "#             print(tree_dic)\n",
    "\n",
    "#         print(nodes_rec_frac)\n",
    "    \n",
    "    return tree_dic, nodes_rec_frac, nodes_imp, labels, bin_width\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling the get_tree function with appropriate Inputs\n",
    "\n",
    "The noticeable outputs of get_tree function is also printed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Varun\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n",
      "C:\\Users\\Varun\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree dictionary:\n",
      " {0: (22, 113.15687499999999, None, None), 1: (27, 0.1455, None, None), 2: (21, 20.2275, None, None), 3: (22, 106.88218749999999, None, None), 4: (21, 23.744999999999997, None, None), 5: (7, 0.0691625, None, None), 6: (20, 15.8359375, None, None)}\n",
      "nodes_rec_frac:\n",
      " {0: [281, 180], 1: [275, 29], 2: [6, 151], 3: [268, 9], 4: [7, 20], 5: [5, 6], 6: [1, 145], 7: [258, 4], 8: [10, 5], 9: [6, 1], 10: [1, 19], 11: [5, 0], 12: [0, 6], 13: [1, 0], 14: [0, 145]}\n",
      "nodes_imp:\n",
      " {0: 0.4760000188216693, 1: 0.17258916204986163, 2: 0.07351211002474733, 3: 0.06287062258077136, 4: 0.384087791495199, 5: 0.49586776859504145, 6: 0.013604803903171314}\n",
      "bin_width:\n",
      " {'0': 0.63871875, '1': 0.9240625, '2': 4.4721875, '3': 73.671875, '4': 0.0028771874999999995, '5': 0.010188125, '6': 0.0133375, '7': 0.0062875, '8': 0.005768750000000001, '9': 0.0014309375000000001, '10': 0.075990625, '11': 0.141340625, '12': 0.5591562499999999, '13': 16.7311875, '14': 0.0009192812500000001, '15': 0.004160875, '16': 0.012375, '17': 0.0016496875, '18': 0.002220875, '19': 0.0009045374999999999, '20': 0.8784375, '21': 1.1724999999999999, '22': 6.2746875, '23': 127.15, '24': 0.0047321875, '25': 0.0322096875, '26': 0.039125, '27': 0.00909375, '28': 0.013153125000000002, '29': 0.0047643749999999995}\n",
      "labels:\n",
      " {'B': 0, 'M': 1}\n"
     ]
    }
   ],
   "source": [
    "max_depth = 3\n",
    "\n",
    "total_col = 32\n",
    "\n",
    "# irrrelavant columns\n",
    "rem_col = [0]\n",
    "\n",
    "# label column\n",
    "label_col = [1]\n",
    "\n",
    "bins = 32\n",
    "\n",
    "k = len(rem_col)+len(label_col)\n",
    "\n",
    "\n",
    "train_rdd, test_rdd = raw_rdd.randomSplit([0.8, 0.2], seed = 43)\n",
    "\n",
    "tree_dic, nodes_rec_frac, nodes_imp, labels, bin_width = get_tree(train_rdd, max_depth, total_col, rem_col, label_col, bins)\n",
    "\n",
    "print(\"Tree dictionary:\\n\",tree_dic)\n",
    "\n",
    "print(\"nodes_rec_frac:\\n\",nodes_rec_frac)\n",
    "\n",
    "print(\"nodes_imp:\\n\",nodes_imp)\n",
    "\n",
    "print(\"bin_width:\\n\",bin_width)\n",
    "\n",
    "print (\"labels:\\n\",labels)            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step - 8: Interpreting the tree \n",
    "\n",
    "Call this function to change the tree_dic to a interpretable format as shown below:\n",
    "\n",
    "    {Node # : (feature_at_test, value, if_feature_value<=value: this class, if_feature_value>value: this class )}\n",
    "\n",
    "Example:\n",
    "        \n",
    "    {0:}\n",
    "    \n",
    "Inputs:\n",
    "\n",
    "    max_depth - depth of the tree\n",
    "    \n",
    "    tree_dic - tree_dic form get_tree() function\n",
    "    \n",
    "    nodes_rec_frac - obtained from the get_Infogain() function\n",
    "    \n",
    "    labels - obtained form get_tree() function\n",
    "    \n",
    "Outputs:\n",
    "\n",
    "    tree_dic - modified tree_dic as described above\n",
    "    \n",
    "    leaf_nodes - leaf_nodes class dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leaf nodes dictionary:\n",
      " {7: 0, 8: 0, 9: 0, 10: 1, 11: 0, 12: 1, 13: 0, 14: 1}\n",
      "Tree dictionary:\n",
      " {0: (22, 113.15687499999999, None, None), 1: (27, 0.1455, 'B', None), 2: (21, 20.2275, None, None), 3: (22, 106.88218749999999, None, None), 4: (21, 23.744999999999997, 'B', 'M'), 5: (7, 0.0691625, 'B', 'M'), 6: (20, 15.8359375, 'B', 'M')}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def interpret_tree(max_depth, tree_dic, nodes_rec_frac, labels):\n",
    "    \n",
    "    leaf_labels = {}\n",
    "    \n",
    "    check = 0\n",
    "    \n",
    "    inv_labels = {v:k for k,v in labels.items()}\n",
    "    \n",
    "    for i in range(2*max_depth+1, (2**(max_depth+1))-1):\n",
    "        \n",
    "            # Selecting leaf nodes class based on max num of records at the leaf nodes\n",
    "            \n",
    "            leaf_labels[i] = nodes_rec_frac[i].index(max(nodes_rec_frac[i]))  \n",
    "            \n",
    "    for i in range(2*max_depth+1, (2**(max_depth+1))-1,2):\n",
    "        \n",
    "        l_label = inv_labels[leaf_labels[i]]\n",
    "        \n",
    "        r_label = inv_labels[leaf_labels[i+1]]\n",
    "        \n",
    "        if leaf_labels[i] == leaf_labels[i+1]:\n",
    "            \n",
    "            father_node = int((i-1)/2)\n",
    "            \n",
    "            grandfather_node = int((father_node-1)/2)\n",
    "            \n",
    "            if father_node%2!=0:\n",
    "                \n",
    "                tree_dic[grandfather_node] = (tree_dic[grandfather_node][0],tree_dic[grandfather_node][1],\\\n",
    "                                           l_label,tree_dic[grandfather_node][3])\n",
    "            else:\n",
    "                \n",
    "                tree_dic[grandfather_node] = (tree_dic[grandfather_node][0],tree_dic[grandfather_node][1],\\\n",
    "                                           tree_dic[grandfather_node][2],r_label)\n",
    "                \n",
    "        else:\n",
    "\n",
    "                father_node = int((i-1)/2)\n",
    "            \n",
    "                tree_dic[father_node] = (tree_dic[father_node][0],tree_dic[father_node][1],\\\n",
    "                                           l_label,tree_dic[father_node][3])\n",
    "                \n",
    "                tree_dic[father_node] = (tree_dic[father_node][0],tree_dic[father_node][1],\\\n",
    "                                           tree_dic[father_node][2],r_label)\n",
    "\n",
    "            \n",
    "            \n",
    "    return leaf_labels, tree_dic\n",
    "\n",
    "leaf_labels, tree_dic = interpret_tree(max_depth, tree_dic, nodes_rec_frac, labels)\n",
    "\n",
    "print(\"leaf nodes dictionary:\\n\",leaf_labels)\n",
    "\n",
    "print( \"Tree dictionary:\\n\",tree_dic)\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step - 9: Prediction function\n",
    "\n",
    "This function is used to predict the labels of rany given row.\n",
    "\n",
    "Inputs:\n",
    "\n",
    "    tree_dic - the modified tree_dic\n",
    "    \n",
    "    test_rdd - rdd/data upon which it should be tested\n",
    "    \n",
    "    max_depth - max depth of the tree\n",
    "    \n",
    "    k - number of irrelevant columns other than features like ID and class\n",
    "    \n",
    "    label_col - column in which label is present\n",
    "    \n",
    "Outputs:\n",
    "\n",
    "    p_test_rdd - rdd with predicted class is added to class column as follows:\n",
    "    \n",
    "        ['ID', 'M,M',...]\n",
    "        \n",
    "        where first 'M' is the actual label and second 'M' is the predicted label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['84300903', 'M,M', '19.69', '21.25', '130', '1203', '0.1096', '0.1599', '0.1974', '0.1279', '0.2069', '0.05999', '0.7456', '0.7869', '4.585', '94.03', '0.00615', '0.04006', '0.03832', '0.02058', '0.0225', '0.004571', '23.57', '25.53', '152.5', '1709', '0.1444', '0.4245', '0.4504', '0.243', '0.3613', '0.08758']\n"
     ]
    }
   ],
   "source": [
    "def predict(tree_dic, test_rdd, max_depth, k, label_col):\n",
    "    \n",
    "    bc_max_depth = sc.broadcast(max_depth)    \n",
    "    bc_tree_dic = sc.broadcast(tree_dic)\n",
    "    bc_k = sc.broadcast(k)\n",
    "    bc_label_col = sc.broadcast(label_col)\n",
    "    \n",
    "    def predict_mapper(x):\n",
    "        \n",
    "        x = x.split(\",\")\n",
    "        l_max_depth = bc_max_depth.value\n",
    "        l_tree_dic = bc_tree_dic.value\n",
    "        l_k = bc_k.value\n",
    "        l_label_col = bc_label_col.value\n",
    "        i = 0\n",
    "        \n",
    "        while(i<2**(l_max_depth+1)-1):\n",
    "            \n",
    "            feature, val, l_label, r_label = tree_dic[i]\n",
    "            \n",
    "            if float(x[feature+l_k]) <= val:\n",
    "                \n",
    "                if l_label == None:\n",
    "                    \n",
    "                    i = 2*i+1\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    predicted_label = l_label\n",
    "                    \n",
    "                    break\n",
    "                    \n",
    "            else:\n",
    "                \n",
    "                if r_label == None:\n",
    "                    \n",
    "                    i = 2*i+2\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    predicted_label = r_label\n",
    "                    \n",
    "                    break\n",
    "                    \n",
    "        x[l_label_col] = x[l_label_col]+\",\"+predicted_label \n",
    "        \n",
    "        return x\n",
    "    \n",
    "    p_test_rdd = test_rdd.map(predict_mapper)\n",
    "    \n",
    "    return p_test_rdd\n",
    "    \n",
    "    \n",
    "p_test_rdd = predict(tree_dic, test_rdd, max_depth, k, label_col[0])\n",
    "\n",
    "p_train_rdd = predict(tree_dic, train_rdd, max_depth, k, label_col[0])\n",
    "\n",
    "print(p_test_rdd.first())\n",
    "                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step - 10 : Computing confusion matrix\n",
    "\n",
    "This computation is made easier by adding the predicted class label to the column class as discussed above. Now Mapper just throws that column and reducer will add by key to produce the confusion matrix as shown in the example.\n",
    "\n",
    "Inputs:\n",
    "\n",
    "    p_test_rdd - output from the predict()\n",
    "    \n",
    "    label_col - label column \n",
    "    \n",
    "Output:\n",
    "\n",
    "    confusion_mat_rdd - confusion matrix in the form of rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data confusion matrix: [('M,M', 28), ('M,B', 4), ('B,B', 72), ('B,M', 4)]\n",
      "Train data confusion matrix: [('M,M', 170), ('M,B', 10), ('B,B', 280), ('B,M', 1)]\n"
     ]
    }
   ],
   "source": [
    "def confusion_mat(p_test_rdd, label_col):\n",
    "    \n",
    "    bc_label_col = sc.broadcast(label_col)\n",
    "    \n",
    "    def confusion_mat_mapper(x):\n",
    "        \n",
    "        l_label_col = bc_label_col.value\n",
    "        \n",
    "        return(x[l_label_col],1)\n",
    "    \n",
    "    confusion_mat_rdd = p_test_rdd.map(confusion_mat_mapper)\\\n",
    "                                  .reduceByKey(add)\\\n",
    "                                  .collect()\n",
    "    \n",
    "    return confusion_mat_rdd\n",
    "\n",
    "confusion_mat_rdd_test = confusion_mat(p_test_rdd, label_col[0])\n",
    "\n",
    "confusion_mat_rdd_train = confusion_mat(p_train_rdd, label_col[0])\n",
    "\n",
    "print(\"Test data confusion matrix:\", confusion_mat_rdd_test)\n",
    "\n",
    "print(\"Train data confusion matrix:\", confusion_mat_rdd_train)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conlusions:\n",
    "\n",
    "The validation is assumed to be random sampling. It did yield good results as seen from the confusion matrix above:\n",
    "    \n",
    "    The key's first letter indicates the actual class and the next letter is the predicted class\n",
    "    \n",
    "    The value is the number of reco  \n",
    "    \n",
    "From the above we can see that the results are satisfactory.\n",
    "\n",
    "**What an exciting project!!!**\n",
    "\n",
    "                                                                                                    Author:\n",
    "                                                                                                    \n",
    "                                                                                                    Varun Raj Rayabarapu\n",
    "                                                                                                    University of Cincinnati"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
