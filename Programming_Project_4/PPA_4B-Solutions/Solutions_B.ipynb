{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment - 4 B Solution\n",
    "\n",
    "## 4 A\n",
    "\n",
    "Use the MLLib API of Spark to construct a decision tree for the Breast Cancer Diagnostic data (Data-Link1) (we call it dataset1), available from the UC-Irvine ML repository. Select appropriate parameters to generate only a 3-level deep decision tree. Submit the following.\n",
    "\n",
    "a.\tYour program code.\n",
    "\n",
    "b.\tThe choice of parameters and attribute selection metric (Gini index, info gain, etc.) used.\n",
    "\n",
    "c.\tAny assumptions made.\n",
    "\n",
    "d.\tValidation and Train/Test Strategy used.\n",
    "\n",
    "e.\tDecision tree Obtained.\n",
    "\n",
    "f.\tPerformance shown by the confusion matrix.\n",
    "\n",
    "## 4 B\n",
    "\n",
    "Now use your own code to build a decision tree in Spark. Model your algorithm based on the homework assignment you did for designing the decision tree learning algorithm. Use excactly the same parameter choices as used in (1.) above. \n",
    "\n",
    "a.\tSubmit the same items (1.a-1.f) as for the question above.\n",
    "\n",
    "b.\tReproduce the results from the 1.e an d 1.f from the previous question and compare with the outputs obtained by your algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "b. The choice of parameters:\n",
    "\n",
    "    Max_depth = 3\n",
    "    \n",
    "    Attribute selection metric = Gini Index\n",
    "    \n",
    "    \n",
    "c. Any Assumptions made:\n",
    "\n",
    "    1. Must use only spark rdd's\n",
    "    \n",
    "    2. The class with maximum records out of two classes at leaf nodes is chosen as the label that decision tree predicts.\n",
    "\n",
    "\n",
    "d. Validation: \n",
    "\n",
    "Initially the data is randomly split into test and train. The data is trained on this train dataset to obtain the tree, which is then used to predicted on the test data.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Break down of the code with working example:\n",
    "\n",
    "**Primary Goal in generating decision tree:**\n",
    "\n",
    "Using spark to get the numbers in the table shown below for every node:\n",
    "\n",
    "This table shows the number of records that are less than or equal as well as greater than the split value for each feature. Given this it is easier to compute the Information gain for each feature by split value.\n",
    "\n",
    "![cap3.PNG](cap3.PNG)\n",
    "\n",
    "**What I need?**\n",
    "\n",
    "Split_Val for each feature: This is taken as the bin's upper limit.\n",
    "\n",
    "    Example: there is a bin from value 2 to 4: 4 is the upper limit of the bin and taken as the split value\n",
    "    \n",
    "If the number of bins is 5 it has 5 split values which are the upper limits of these bins. \n",
    "\n",
    "    Example: \n",
    "    \n",
    "    bin #: lwr - upr    \n",
    " \n",
    "    bin 1: >=2 - =<4 // read as greater than or equal to 2 and less than or equal to 4 \n",
    "    bin 2: >4  - =<6 // read as greater than 4 and less than or equal to 6\n",
    "    bin 3: >6  - =<8\n",
    "    bin 4: >8  - =<10\n",
    "    bin 5: >10 - =<12\n",
    "    \n",
    "    The split values are : 4, 6, 8, 10 and 12 for this feature\n",
    "    \n",
    "**Argument - 1: If a record belongs to a bin#x then it is less than or equal to the upper limit of the bins#y, where y >= x. \n",
    "And also, greater than the bin#z where z < x**\n",
    "\n",
    "**How I did it?**\n",
    "\n",
    "1. Get the min and max values of each bin to compute bin_width and know your upper limits.\n",
    "\n",
    "2. Replace the real valued features with the bin numbers to which they belong.\n",
    "\n",
    "3. Use the Argument - 1, to get the numbers in the table shown above:\n",
    "    \n",
    "4. After getting the numbers in the table using spark.\n",
    "\n",
    "5. Collect and transform it into 4-d numpy array (features, bins#, 2 , class_labels). This form will be easy to get the information gain.\n",
    "\n",
    "6. Get the max value from the array of information gain (features, bins#)\n",
    "\n",
    "7. Store the corresponding feature, and bin# to compute the Split_Val which is the upper limit of the bin.\n",
    "\n",
    "8. Split the data into two child the one on left has all the records which have feature's value lesser than the one selected in the above step. And on the right hand side has all the records which have feature's value greater than the one selected in the above step.\n",
    "\n",
    "9. Now move to the left node and repeat the process of filling the table for this node.\n",
    "\n",
    "10. Continue this process until you get to the desired depth.\n",
    "\n",
    "11. The last level of the tree (leaf node) may contain both the classes. So, when interpreting the decision tree replace it with the class of maximum of records.\n",
    "\n",
    "**How driver function does this?**\n",
    "\n",
    "The driver function is **get_tree().**\n",
    "\n",
    "The working of the driver is shown with an example data:\n",
    "\n",
    "|   ID   |class   |    feature0   |    feature1   |   feature2   |   feature3 |\n",
    "|--------|--------|---------------|---------------|--------------|------------|\n",
    "|   1    |   M    |       2       |        3      |       7      |      10    |\n",
    "|   2    |   B    |       3       |        5      |       6      |       2    |\n",
    "|   3    |   M    |       5       |        8      |       2      |      12    |\n",
    "|   4    |   M    |       8       |        6      |       5      |       7    |\n",
    "|   5    |   B    |       12      |        7      |       12     |       4    |\n",
    "\n",
    "This data is loaded as a raw_rdd as shown below from a csv file:\n",
    "\n",
    "raw_rdd -\n",
    "\n",
    "    ['1,M,2,3,7,10','2,B,3,5,6,2','3,M,5,8,2,12','4,M,8,6,5,7', '5,B,12,7,12,4']\n",
    "\n",
    "Then the driver function executes the following stages:\n",
    "\n",
    "#### Stage 1: Find the min and max of each attribute using get_min_max() function.\n",
    "\n",
    "**Note: This stage will execute a sequence of map - reduce tasks to get min and max of each attribute**\n",
    "\n",
    "The driver will call the get_min_max() function to get the min and max of the each attribute:\n",
    "\n",
    "Inputs:\n",
    "\n",
    "    g_rdd - train data rdd\n",
    "    \n",
    "    f_col - number of irrelevant columns like class column and the ID column or the number of feature columns\n",
    "    \n",
    "    k - length of f_col\n",
    "    \n",
    "Outputs:\n",
    "\n",
    "    min_f - a dictionary where the feature number is key and min value is the value.\n",
    "    \n",
    "    max_f - a dictionary where the feature number is key and max value is the value.\n",
    "            \n",
    "we will pass our raw_rdd , f_col: the columns which are not features (array) and k: the length of the f_col array.\n",
    "\n",
    "Sample Inputs:\n",
    "\n",
    "    raw_rdd - ['1,M,2,3,7,10','2,B,3,5,6,2','3,M,5,8,2,12','4,M,8,6,5,7', '5,B,12,7,12,4']\n",
    "    \n",
    "    f_col - [0, 1]\n",
    "    \n",
    "    k - 2\n",
    "\n",
    "Sample outputs:\n",
    "\n",
    "    max_f - { 0:12, 1:8, 2:12, 3:12}\n",
    "    \n",
    "    min_f - { 0:2,  1:3, 2:2, 3:2}\n",
    "    \n",
    "#### Stage 2: Compute the bin width based on the min value, max value, and number of bins desired using get_bin_width() function.\n",
    "\n",
    "**Note: This stage will not execute a sequence of map - reduce tasks to get bin width of each attribute**\n",
    "\n",
    "The driver will call the get_bin_width() function to get the bin width for each feature:\n",
    "\n",
    "Inputs:\n",
    "\n",
    "    min_f - from get_min_max()\n",
    "    \n",
    "    max_f - from get_min_max()\n",
    "    \n",
    "    bins - number of bins \n",
    "    \n",
    "Outputs:\n",
    "\n",
    "    bin_width - a dictionary of bin width for each feature\n",
    "    \n",
    "Sample Inputs:\n",
    "\n",
    "    min_f - { 0:12, 1:8, 2:12, 3:12}\n",
    "    \n",
    "    max_f - { 0:2,  1:3, 2:2, 3:2}\n",
    "    \n",
    "    bins - 5\n",
    "    \n",
    "Sample Outputs:\n",
    "\n",
    "    Sample calculation: \n",
    "    \n",
    "        min of feature 0: 2, max of feature 0: 12\n",
    "        \n",
    "        bin_width of feature 0: (12-2)/5 = 2 \n",
    "\n",
    "    bin_width - {0:2, 1:1, 2:2, 3:2}\n",
    "    \n",
    "#### Stage 3: Get the number of classes in the data and create a dictionary like {'B':0, 'M':1}. This dictionary maps each label to a number. This is done in get_labels() function.\n",
    "\n",
    "**Note: This stage will execute a sequence of map - reduce tasks to get unique labels in the data**\n",
    "\n",
    "The function get_labels is called to get the distinct labels in the data by the driver.\n",
    "\n",
    "Inputs:\n",
    "\n",
    "    g_rdd - the train data\n",
    "    \n",
    "    label_col - the label column\n",
    "    \n",
    "Outputs:\n",
    "\n",
    "    label_dic -  a dictionary where labels are key and a number is a value\n",
    "  \n",
    "Sample Inputs:\n",
    "\n",
    "    g_rdd - ['1,M,2,3,7,10','2,B,3,5,6,2','3,M,5,8,2,12','4,M,8,6,5,7', '5,B,12,7,12,4']\n",
    "\n",
    "    label_col - 1\n",
    "    \n",
    "Sample Outputs:\n",
    "\n",
    "    label_dic - {'B':0, 'M':1}\n",
    "    \n",
    "#### Stage 4:  Clean the data: which removes the ID column , replaces the 0 for class 'B' and 1 for class 'M'. Furthermore, it will transform the real valued features into bins using clean_data() function. \n",
    "\n",
    "**Note: This stage will execute a sequence of map - reduce tasks to get clean_rdd **\n",
    "\n",
    "The driver will call the clean_data() function to get the clean rdd which has no ID column , label replaced with a number and the number of the bin a feature value falls into. \n",
    "\n",
    "Inputs:\n",
    "\n",
    "    g_rdd - training data\n",
    "    \n",
    "    label_col - class column\n",
    "    \n",
    "    bin_width - dictionary obtained from the get_bin_width() function\n",
    "    \n",
    "    labels - dictionary obtained from the get_labels() function\n",
    "    \n",
    "    bins - number of bins\n",
    "    \n",
    "    min_f - min_f obtained from the get_min_max() function\n",
    "    \n",
    "Outputs:\n",
    "\n",
    "    clean_rdd - each attribute value is replaced with the bin number\n",
    "    \n",
    "    \n",
    "Sample Inputs:\n",
    "\n",
    "    g_rdd - ['1,M,2,3,7,10','2,B,3,5,6,2','3,M,5,8,2,12','4,M,8,6,5,7', '5,B,12,7,12,4']\n",
    "    \n",
    "    label_col - 1\n",
    "    \n",
    "    bin_width - {0:2, 1:1, 2:2, 3:2}\n",
    "\n",
    "    min_f - { 0:2,  1:3, 2:2, 3:2}\n",
    "    \n",
    "    labels - {'B':0, 'M':1}\n",
    "    \n",
    "    bins - 5\n",
    "    \n",
    "**Note: Mapper task will get label_col, bin_width, min_f and labels broadcasted ** \n",
    "    \n",
    "Sample Outputs:\n",
    "\n",
    "    Sample calculation:\n",
    "    \n",
    "    For 1st element in g_rdd: '1,M,2,3,7,10'\n",
    "    \n",
    "    0th feature min_f[0] = 2 // min value of 0th feature\n",
    "    \n",
    "    bin_width[0] is 2 // bin width of 0th feature \n",
    "    \n",
    "    bins :\n",
    "    \n",
    "    bin #: lwr - upr    \n",
    " \n",
    "    bin 1: >=2 - =<4 // read as greater than or equal to 2 and less than or equal to 4 \n",
    "    bin 2: >4  - =<6 // read as greater than 4 and less than or equal to 6\n",
    "    bin 3: >6  - =<8\n",
    "    bin 4: >8  - =<10\n",
    "    bin 5: >10 - =<12\n",
    "    \n",
    "    Now for attribute 0 of value 2 falls in bin number 1.\n",
    "    \n",
    "    When you multiply attribute bin_width (2) with bin number(1) and add the min value (2) you get the upper limit of corresponding bin as follows:\n",
    "    \n",
    "        upper limit of a feature f of bin# = bin# * bin_width + min\n",
    "    \n",
    "        In this case it is : 1*2 + 2 = 4\n",
    "        \n",
    "        upper limit of bin 1 is 4.\n",
    "        \n",
    "    Repeat the above steps to get bin number for every attribute value in every row.\n",
    "    \n",
    "    You get the following:\n",
    "\n",
    "    [['1,1,1,3,4'],['0,1,2,2,1'],['1,2,5,1,5'],['1,3,3,2,3'],['0,5,4,5,1']]\n",
    "    \n",
    "    The comma separated values of each element in rdd are:\n",
    "    \n",
    "    1st value : label\n",
    "    \n",
    "    2nd value : bin # of attribute 0\n",
    "\n",
    "    3rd value : bin # of attribute 1\n",
    "    \n",
    "    4th value : bin # of attribute 2\n",
    "    \n",
    "    5th value : bin # of attribute 3\n",
    "    \n",
    "    In this rdd you can see that each attribute is replaced by the bin number in which it falls.\n",
    "    \n",
    "    The next step is to convert each element in the above rdd as follows:\n",
    "    \n",
    "    [label, (feature#1,bin#,bin#min,bin#max),(feature#2,bin#,bin#min,bin#max)(feature#3,bin#,bin#min,bin#max)]...]\n",
    "    \n",
    "    [['1','0,1,1,5','1,1,1,5','2,3,1,5','3,4,1,5'],['0','0,1,1,5','1,2,1,5','2,2,1,5','3,1,1,5'],\n",
    "     ['1','0,2,1,5','1,5,1,5','2,1,1,5','3,5,1,5'],['1','0,3,1,5','1,3,1,5','2,2,1,5','3,3,1,5'],\n",
    "     ['0','0,5,1,5','1,4,1,4','2,5,1,5','3,1,1,5']]\n",
    "     \n",
    "     label -  label of the record\n",
    "     \n",
    "     feature# - feature number \n",
    "     \n",
    "     bin # - bin number to which it belongs to\n",
    "     \n",
    "     bin # min - min number of bin which is 1\n",
    "     \n",
    "     bin # max -  max number of bin which is 5\n",
    "     \n",
    "     This is the rdd that clean_data function returns.\n",
    "    \n",
    "#### Stage 5 : Get the numbers  in the table similar to the one shown in the fig 1 using get_num_rec() function.\n",
    "\n",
    "**Note: This stage will execute a sequence of map - reduce tasks to get num_rec_ar (a numpy array which stores the table info ) **\n",
    "\n",
    "What is this fig 1 :\n",
    "\n",
    "![cap3.PNG](cap1.PNG)\n",
    "\n",
    "**Argument 1:**\n",
    "\n",
    "The bin number of record 1 and attribute 2 is 3 as in clean_dd:\n",
    "    \n",
    "        [ '1', '0,1,1,5', '1,1,1,5', '2,3,1,5', '3,4,1,5'].\n",
    "\n",
    "Its bin number is less than or equal to the bin numbers: [3,4,5]\n",
    "\n",
    "also greater than the bin numbers : [1,2]\n",
    "\n",
    "The same thing can be interpreted as:\n",
    "\n",
    "The value of the attribute is less than or equal to the upper limit of bins [3,4,5] since it falls in the bin 3 so this record will be counted on the =< side of the above table for these bin numbers \n",
    "\n",
    "But its value is also greater than the upper limits of bin numbers : [1,2] so this record will be counted on the > side of the above table for these bin numbers.\n",
    "\n",
    "Explanation:\n",
    "\n",
    "upper limits of bins for attribute 3:\n",
    "\n",
    "bin 1: 4\n",
    "\n",
    "bin 2: 6\n",
    "\n",
    "bin 3: 8\n",
    "\n",
    "bin 4: 10\n",
    "\n",
    "bin 5: 12\n",
    "\n",
    "Given record 1 and attribute 2 is in bin 3. Therefore, it is less than or equal to its bin upper limit 8. Also, it is less than or equal to the bins:[4,5] upper limit [10,12] respectively. Similarly, it is greater than the bins:[1,2] upper limit [4,6].\n",
    "\n",
    "This argument is key in obtaining the numbers in the table.\n",
    "\n",
    "**How Argument - 1 is used to get the values in the table?**\n",
    "\n",
    "Explanation with example:\n",
    "\n",
    "Lets take the record 1, the first element in the clean_rdd:\n",
    "\n",
    "get_num_rec_mapper1:\n",
    "\n",
    "    This mapper will take each element in clean_rdd: ['1','0,1,1,5','1,1,1,5','2,3,1,5','3,4,1,5']\n",
    "    \n",
    "    converted into: \n",
    "    (key=label, value=[(feature#1,bin#,bin#min,bin#max),(feature#2,bin#,bin#min,bin#max)(feature#3,bin#,bin#min,bin#max)])\n",
    "\n",
    "    ('1', ['0,1,1,5','1,1,1,5','2,3,1,5','3,4,1,5'])\n",
    "    \n",
    "flatmMapValues:\n",
    "    \n",
    "    ('1', ['0,1,1,5','1,1,1,5','2,3,1,5','3,4,1,5'])\n",
    "\n",
    "    => [('1','0,1,1,5'),('1','1,1,1,5'),('1','2,3,1,5'),('1','3,4,1,5')]\n",
    "    \n",
    "get_num_rec_mapper2:\n",
    "\n",
    "    This mapper will use the argument 1 as follows:\n",
    "    \n",
    "    It will take a elemnt from the above rdd: ('1', '0,1,1,5')\n",
    "    \n",
    "    create new list z = []\n",
    "    \n",
    "    Iterate \"i\" (a value) from bin min number to max number:\n",
    "        \n",
    "        if bin_number_of_attribute=<i:\n",
    "        \n",
    "            add this to z:\n",
    "                \n",
    "                'feature#,i,0,class'\n",
    "                \n",
    "            ## Here we are making sure that this row is accounted for the case when checked for bin#=<bin_upper_limit_of_i\n",
    "                \n",
    "        else :\n",
    "        \n",
    "            add this to z:\n",
    "            \n",
    "                'feature#,i,1,class'\n",
    "                \n",
    "            ## Here we are making sure that this row is accounted for the case when checked for bin#>bin_upper_limit_of_i\n",
    "                \n",
    "         \n",
    "    The z list will look like this for the example element:\n",
    "    \n",
    "    ['0,1,0,1','0,2,0,1','0,3,0,1','0,4,0,1','0,5,0,1']\n",
    "    \n",
    "    z list for another example element : ('1','2,3,1,5')\n",
    "    \n",
    "    ['2,1,1,1','2,2,1,1','2,3,0,1','2,4,0,1','2,5,0,1']\n",
    "    \n",
    "    z list is returned\n",
    "    \n",
    "flatMap the above rdd:\n",
    "\n",
    "    ['0,1,0,1','0,2,0,1','0,3,0,1','0,4,0,1','0,5,0,1',...'2,1,1,1','2,2,1,1','2,3,0,1','2,4,0,1','2,5,0,1'...]\n",
    "    \n",
    "Map each element in the above rdd as follows:\n",
    "\n",
    "    [('0,1,0,1',1),('0,2,0,1',1),('0,3,0,1',1).....]\n",
    "    \n",
    "    where key is the element of the rdd and the value is 1\n",
    "\n",
    "reduceByKey and add to get:\n",
    "\n",
    "    [('0,1,0,0',1),('0,1,0,1',1),('0,1,1,0',1),('0,1,1,1',2)...]\n",
    "    \n",
    "    the key signifies the following:\n",
    "        \n",
    "        When we break the key by comma:\n",
    "        \n",
    "            1st value: feature #\n",
    "            \n",
    "            2nd value: bin #\n",
    "            \n",
    "            3rd value: \n",
    "                       1 indicates all the records whose > bin # \n",
    "                       0 indicates all the records whose =< bin#\n",
    "            \n",
    "            4th value: class label\n",
    "            \n",
    "    That is the element '0,1,0,0' will give the value for the first row and first column in the table shown in fig 1.\n",
    "    \n",
    "![cap3.PNG](cap2.PNG)\n",
    "        \n",
    "Convert the above rdd into numpy array as num_rec_ar of shape (features, bins, 2, class_labels)\n",
    "\n",
    "The 2 in the above shape signifies (=< and > bin#)\n",
    "\n",
    "This numpy array given to stage 6 to get the info gain.\n",
    "\n",
    "![cap3.PNG](cap4.PNG)\n",
    "\n",
    "#### Stage 6: Get Info gain of each and every attribute, and bin at test into a numpy array using get_Infogain_ar() function.\n",
    "\n",
    "Use the numpy array is passed to get_Infogain_ar() function to get the Info gain for each attribute and bin. This Infogain_ar is of shape (features, bins). \n",
    "\n",
    "Get the index where the max value for Info gain appears: \n",
    "\n",
    "For example if the index is (0,3), it indicates that the feature '0' and bin 3 upper limit value has the maximum info gain.\n",
    "\n",
    "bin 3 upper limit = 3*bin_width+min_f = 3*2+2 = 8 \n",
    "\n",
    "So, the test attribute is 3 and value is 8.\n",
    "\n",
    "**Stage 7a: After getting Info gain numpy array. Find the one which is the maximum value and make corresponding feature as a decision feature with bin*bin_width + min as the value based on the which it will proceed to the next node.**\n",
    "\n",
    "**Stage 7b: Store this information in the tree_dic dictionary as {Node# : (feature, bin*bin_width+min_f, None, None)}**\n",
    "\n",
    "**Stage 7c: Store the nodes impurities a.k.a the number of recs per class on the left and right child from the table obatined from the get_num_rec() function as numpy array of shape (features, bins, 2, # of classes).**\n",
    "\n",
    "**Stage 7d: Split the rdd into two rdd's:**\n",
    "\n",
    "            l_rdd - this is the rdd which contains all the rows that contain value of the feature selected above =< bin# (bin*bin_width + min).\n",
    "\n",
    "            r_rdd - this is the rdd which contains all the rows that contain value of the feature selected above > bin# (bin*bin_width + min).\n",
    "            \n",
    "The following modifications are important to the rdd after splitting:\n",
    "\n",
    "Example :\n",
    "\n",
    "    clean_rdd :\n",
    "    \n",
    "    [['1','0,1,1,5','1,1,1,5','2,3,1,5','3,4,1,5'],['0','0,1,1,5','1,2,1,5','2,2,1,5','3,1,1,5'],\n",
    "     ['1','0,2,1,5','1,5,1,5','2,1,1,5','3,5,1,5'],['1','0,3,1,5','1,3,1,5','2,2,1,5','3,3,1,5'],\n",
    "     ['0','0,5,1,5','1,4,1,4','2,5,1,5','3,1,1,5']]\n",
    "\n",
    "If the feature '0' and bin '2' has max Info gain then:\n",
    "\n",
    "    feature 0 bin# of the 1st row is 1 (=<2) \n",
    "    \n",
    "        ['1','0,1,1,5','1,1,1,5','2,3,1,5','3,4,1,5']\n",
    "    \n",
    "            => ['1','0,1,1,2','1,1,1,5','2,3,1,5','3,4,1,5']\n",
    "     \n",
    "            Max bin of the feature '0' is changed from the 1 to 2\n",
    "            \n",
    "    feature 0 bin# of the 4th row is 3 (>2)\n",
    "    \n",
    "        ['1','0,3,1,5','1,3,1,5','2,2,1,5','3,3,1,5']\n",
    "\n",
    "             => ['1','0,3,3,5','1,3,1,5','2,2,1,5','3,3,1,5']\n",
    "             \n",
    "             Min bin of the feature '0' is changed from 1 to 3 \n",
    "\n",
    "**Stage 7e: Save the above two rdds which will be given to get_num_rec() function. In the next iteration to get the similar table as we got above. These rdd's are stored in the dictionary nodes_rdd[2*i+1: l_rdd, 2*i+2: r_rdd]**\n",
    "\n",
    "**Stage 7f: Repeat the 7a - 7e on the next nodes rdd in nodes_rdd dictionary until you get the tree of desired depth.**\n",
    "    \n",
    "**Stage 8: Use interpret_tree() function to transform the obtained tree_dic to interpretable decision tree for the given max depth.**\n",
    "\n",
    "**Use predict() to predict the test data.**\n",
    "    \n",
    "**Use confusion_mat() to get the confusion matrix.**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Data into an rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['842302,M,17.99,10.38,122.8,1001,0.1184,0.2776,0.3001,0.1471,0.2419,0.07871,1.095,0.9053,8.589,153.4,0.006399,0.04904,0.05373,0.01587,0.03003,0.006193,25.38,17.33,184.6,2019,0.1622,0.6656,0.7119,0.2654,0.4601,0.1189']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data into an rdd\n",
    "\n",
    "raw_rdd = sc.textFile(\"wdbc.csv\")\n",
    "\n",
    "raw_rdd.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step -1: Getting max and min of all the columns\n",
    "\n",
    "The following function will return the column number and its max as well as min value for that column.\n",
    "\n",
    "Inputs:\n",
    "\n",
    "    g_rdd - train data rdd\n",
    "    \n",
    "    f_col - number of irrelevant columns like class column and the ID column or the number of feature columns\n",
    "    \n",
    "    k - length of f_col\n",
    "    \n",
    "Outputs:\n",
    "\n",
    "    min_f - a dictionary where the feature number is key and min value is the value.\n",
    "    \n",
    "    max_f - a dictionary where the feature number is key and max value is the value.\n",
    "    \n",
    "    Example output:\n",
    "    \n",
    "        min_f - {0:2.5} \n",
    "        \n",
    "        max_f - {0:5.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get Max and Min for each column:\n",
    "\n",
    "# finding Max and Min of each feature using rdd:\n",
    "def get_min_max(g_rdd, f_col, k):\n",
    "    def min_max_mapper(x):\n",
    "    \n",
    "        x = x.split(\",\")\n",
    "        l_f_col = bc_f_col.value\n",
    "        l_k = bc_k.value\n",
    "        y = []\n",
    "        for i in range(0, len(x)):\n",
    "            if i in l_f_col:\n",
    "                continue\n",
    "            else:\n",
    "                y.append(str(i-k)+\"$\"+x[i])\n",
    "        return y\n",
    "\n",
    "    bc_k = sc.broadcast(k)\n",
    "\n",
    "    bc_f_col = sc.broadcast(f_col)\n",
    "\n",
    "    max_f_rdd = g_rdd.map(min_max_mapper)\\\n",
    "                       .flatMap(lambda x: x)\\\n",
    "                       .map(lambda x: (x.split(\"$\")[0],float(x.split(\"$\")[1])))\\\n",
    "                       .reduceByKey(max)\n",
    "\n",
    "\n",
    "    max_f = max_f_rdd.collect()\n",
    "    \n",
    "    max_fv = {}\n",
    "    \n",
    "    for i in range(0,len(max_f)):\n",
    "        max_fv[max_f[i][0]] = max_f[i][1]\n",
    "    \n",
    "    min_f_rdd = g_rdd.map(min_max_mapper)\\\n",
    "                   .flatMap(lambda x: x)\\\n",
    "                   .map(lambda x: (x.split(\"$\")[0],float(x.split(\"$\")[1])))\\\n",
    "                   .reduceByKey(min)\n",
    "\n",
    "    min_f = min_f_rdd.collect()\n",
    "    \n",
    "    min_fv = {}\n",
    "    \n",
    "    for i in range(0,len(max_f)):\n",
    "        min_fv[min_f[i][0]] = min_f[i][1]\n",
    "        \n",
    "        \n",
    "    return (min_fv,max_fv)\n",
    "\n",
    "# # Uncomment the following code to see what this function does\n",
    "# rem_col = [0]\n",
    "\n",
    "# label_col = [1]\n",
    "\n",
    "# f_col = rem_col + label_col\n",
    "\n",
    "# k = len(rem_col)+len(label_col)\n",
    "    \n",
    "# bins = 32\n",
    "\n",
    "# min_f, max_f = get_min_max(raw_rdd, f_col,k)\n",
    "\n",
    "# print(\"min_f:\",min_f)\n",
    "\n",
    "# print(\"max_f:\",max_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step -2 : Getting the bin width for each feature\n",
    "\n",
    "This function will return the bin_width for each feature.\n",
    "\n",
    "Inputs:\n",
    "\n",
    "    min_f - from get_min_max()\n",
    "    \n",
    "    max_f - from get_min_max()\n",
    "    \n",
    "    bins - number of bins \n",
    "    \n",
    "Outputs:\n",
    "\n",
    "    bin_width - a dictionary of bin width for each feature\n",
    "    \n",
    "    Example: {0:0.125}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the bin width\n",
    "\n",
    "# bins = 32\n",
    "\n",
    "def get_bin_width(min_f, max_f, bins):\n",
    "    \n",
    "    bin_width = {}\n",
    "\n",
    "    for i in range(0, len(max_f)):\n",
    "    \n",
    "        bin_width[str(i)]=(max_f[str(i)]-min_f[str(i)])/bins\n",
    "       \n",
    "    return bin_width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step - 3: Get the class labels in the dataset\n",
    "\n",
    "This function will make a dictionary of the class labels, where labels are key and a number is a value.\n",
    "\n",
    "Inputs:\n",
    "\n",
    "    g_rdd - the train data\n",
    "    \n",
    "    label_col - the label column\n",
    "    \n",
    "Outputs:\n",
    "\n",
    "    label_dic -  a dictionary where labels are key and a number is a value\n",
    "    \n",
    "    Example: {'B':0, 'M':1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(g_rdd, label_col):\n",
    "    bc_label_col = sc.broadcast(label_col)\n",
    "    \n",
    "    def get_labels_mapper(x):\n",
    "        x = x.split(\",\")\n",
    "        l_label_col = bc_label_col.value[0]\n",
    "        return str(x[l_label_col])\n",
    "    \n",
    "    labels_rdd = g_rdd.map(get_labels_mapper)\\\n",
    "                        .distinct()\n",
    "    labels = labels_rdd.collect()\n",
    "    \n",
    "    labels.sort()\n",
    "    \n",
    "    labels_dic = {}\n",
    "    \n",
    "    for i in range(0,len(labels)):\n",
    "        labels_dic[labels[i]] = i\n",
    "\n",
    "    return labels_dic\n",
    "\n",
    "# Uncomment the following to see what this function does\n",
    "# label_col = [1]\n",
    "\n",
    "# labels = get_labels(raw_rdd, label_col)\n",
    "\n",
    "# print(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step - 4: Getting the binned form of data \n",
    "\n",
    "This function will create a new cleaned rdd where each attribute value is replaced with the bin number. This bin number is chose in such a way that when you multiply it with the bin_width and add the min of that attribute you get the upper limit of the bin in which it is present.\n",
    "\n",
    "For example:\n",
    "\n",
    "    attribute value = 5\n",
    "    \n",
    "    bin_width is 2\n",
    "    \n",
    "    bins :\n",
    "    \n",
    "    bin 1: 0-2\n",
    "    bin 2: 2-4\n",
    "    bin 3: 4-6\n",
    "    bin 4: 6-8\n",
    "    bin 5: 8-10\n",
    "    \n",
    "    Now 5 falls in bin number 3.\n",
    "    \n",
    "    When you multiply attribute bin_width (2) with bin number(3) and add the min value (0) you get the upper limit of corresponding bin as follows:\n",
    "    \n",
    "        In this case it is : 3*2 + 0= 6\n",
    "        \n",
    "    This information will be further used in the next steps to fill in the data for tabel in fig 4.16.\n",
    "    \n",
    "Inputs:\n",
    "\n",
    "    g_rdd - training data\n",
    "    \n",
    "    label_col - class column\n",
    "    \n",
    "    bin_width - dictionary obtained from the get_bin_width() function\n",
    "    \n",
    "    labels - dictionary obtained from the get_labels() function\n",
    "    \n",
    "    bins - number of bins\n",
    "    \n",
    "    min_f - min_f obtained from the get_min_max() function\n",
    "    \n",
    "Outputs:\n",
    "\n",
    "    clean_rdd - each attribute value is replaced with the bin number\n",
    "    \n",
    "    Example: [['0','0,2,1,32', '1,5,1,32', '2,7,1,32'...],['1','0,3,1,32', '1,6,1,32', '2,7,1,32']]\n",
    "    \n",
    "    first column : '0' => class\n",
    "    \n",
    "    second column: feature       => 0\n",
    "                   bin_number    => 2\n",
    "                   min_bin_number=> 1\n",
    "                   max_bin_number=> 32\n",
    "                   \n",
    "    Similar interpretation for all the other columns\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from math import ceil, floor\n",
    "\n",
    "def clean_data(g_rdd, rem_col, label_col, bin_width, labels, bins, min_f):\n",
    "    k = len(rem_col)+len(label_col)\n",
    "    bc_rem_col = sc.broadcast(rem_col)\n",
    "    bc_label_col = sc.broadcast(label_col)\n",
    "    bc_bin_width = sc.broadcast(bin_width)\n",
    "    bc_k = sc.broadcast(k)\n",
    "    bc_labels = sc.broadcast(labels)\n",
    "    bc_bins = sc.broadcast(bins)\n",
    "    bc_min_f = sc.broadcast(min_f)\n",
    "    \n",
    "    def clean_data_mapper(x):\n",
    "        \n",
    "        x = x.split(\",\")\n",
    "        l_rem_col = bc_rem_col.value\n",
    "        l_k = bc_k.value\n",
    "        l_bin_width = bc_bin_width.value\n",
    "        l_label_col = bc_label_col.value\n",
    "        l_labels = bc_labels.value\n",
    "        l_bins = bc_bins.value\n",
    "        l_min_f = bc_min_f.value\n",
    "        y = []\n",
    "        for i in range(0, len(x)):\n",
    "            if i in l_rem_col:\n",
    "                #y.append(x[i])\n",
    "                continue\n",
    "            elif i in l_label_col:\n",
    "                y.append(str(l_labels[x[i]]))\n",
    "            else:\n",
    "                z = (float(x[i])-l_min_f[str(i-l_k)])/l_bin_width[str(i-l_k)]\n",
    "                if floor(z)<z<ceil(z):\n",
    "                    z = ceil(z)\n",
    "                if z==0:\n",
    "                    z = 1\n",
    "                y.append(str(i-l_k)+\",\"+str(int(z))+\",\"+\"1\"+\",\"+str(l_bins))\n",
    "        return y\n",
    "\n",
    "    clean_rdd = g_rdd.map(clean_data_mapper)\n",
    "        \n",
    "    return clean_rdd\n",
    "\n",
    "# # Uncomment the following and run to see what this function does\n",
    "# rem_col = [0]\n",
    "\n",
    "# label_col = [1]\n",
    "\n",
    "# f_col = rem_col + label_col\n",
    "\n",
    "# k = len(rem_col)+len(label_col)\n",
    "    \n",
    "# bins = 32\n",
    "\n",
    "# min_f, max_f = get_min_max(f_col,k)\n",
    "    \n",
    "# bin_width = get_bin_width(min_f, max_f, bins)\n",
    "    \n",
    "# labels = get_labels(label_col)\n",
    "    \n",
    "# b=clean_data(raw_rdd, rem_col, label_col, bin_width, labels, bins, min_f)\n",
    "\n",
    "# b = b.filter(lambda x: x[2].split(\",\")[2]>\"32\")\n",
    "\n",
    "# print(min_f)\n",
    "\n",
    "# print(max_f)\n",
    "\n",
    "# print(bin_width)\n",
    "\n",
    "# print(b.first())\n",
    "\n",
    "# print(raw_rdd.first())"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step -5: Getting the numbers to fill the table like shown in the figure.\n",
    "\n",
    "The numbers are obatained using the logic discussed below:\n",
    "\n",
    "    In the Step -4 we got the rdd as shown below:\n",
    "    \n",
    "        [['0','0,2,1,32', '1,5,1,32', '2,7,1,32'...],['1','0,3,1,32', '1,6,1,32', '2,7,1,32']]\n",
    "        \n",
    "        Now each row in rdd is expanded as follows:\n",
    "        \n",
    "            ['0','0,2,1,32', '1,5,1,32', '2,7,1,32'...]\n",
    "            \n",
    "       =>   ('0', ['0,2,1,32', '1,5,1,32', '2,7,1,32'...])\n",
    "            \n",
    "       =>   ['0', '0,2,1,32'], ['0','1,5,1,32',], ['0','2,7,1,32']..\n",
    "            \n",
    "       =>   ('0,1,0,0',1), ('0,2,0,0',1), ('0,3,1,0',1), ('0,4,1,0',1)..\n",
    "            \n",
    "            In the above key - value pairs the key has the following four parts separated by \",\":\n",
    "            \n",
    "            ('0,1,0,0',1), ('0,2,0,0',1), ('0,3,1,0',1):\n",
    "            \n",
    "            for the current row, column '0' belongs to bin 2, so:\n",
    "                \n",
    "                It is greater than the upper limit of 1*bin_width + min=> this is denoted by '0' at the third position. \n",
    "                \n",
    "                It is lesser than the upper limit of 3*bin_width + min=> this is denoted byt '1' at the third poistion.\n",
    "                \n",
    "            The fourth position is the class label, in this case it is '0'.\n",
    "    \n",
    "    When we reduce by key and add, we get enough information to fill the following table of fig 1:\n",
    "    \n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we obtain the values, we will use 4 dimensional numpy array to visualize the above table.\n",
    "\n",
    "shape of numpy array: (features, bins, 2, class)\n",
    "\n",
    "2 denotes the =< and >\n",
    "\n",
    "Inputs:\n",
    "\n",
    "    g_rdd - an rdd/data at a node to determine the max info gain\n",
    "    \n",
    "    label_col - class label column\n",
    "    \n",
    "    bin - number of bins\n",
    "    \n",
    "    f_num - the number of features\n",
    "    \n",
    "    labels_num - number of classes\n",
    "    \n",
    "Output:\n",
    "\n",
    "    num_rec_ar - a 4-d numpy array realizing the above table of shape (features, bins, 2, class)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add\n",
    "import numpy as np\n",
    "\n",
    "def get_num_rec(g_rdd, label_col, bins, f_num, labels_num):\n",
    "    \n",
    "    b_label_col = sc.broadcast(label_col)\n",
    "    \n",
    "    def get_num_rec_mapper1(x):\n",
    "#         z=[]\n",
    "#         for i in range(0, len(x)):\n",
    "#             if i!=0:\n",
    "#                 z.append(x[i])    \n",
    "        return(x[0],x[1:])\n",
    "\n",
    "    def get_num_rec_mapper2(x):\n",
    "        \n",
    "        z = []\n",
    "        b = list(map(int,x[1].split(\",\")))\n",
    "        x_min = b[2]\n",
    "        x_max = b[3]\n",
    "        x_bin = b[1]\n",
    "        for i in range(x_min,x_max+1):\n",
    "            if x_bin<=i:\n",
    "                z.append((str(b[0])+\",\"+str(i)+\",\"+\"0\"+\",\"+x[0],1))\n",
    "            else:\n",
    "                z.append((str(b[0])+\",\"+str(i)+\",\"+\"1\"+\",\"+x[0],1))\n",
    "        return z\n",
    "\n",
    "    r_rdd = g_rdd.map(get_num_rec_mapper1)\\\n",
    "                       .flatMapValues(lambda x:x)\\\n",
    "                       .map(get_num_rec_mapper2)\\\n",
    "                       .flatMap(lambda x:x) \\\n",
    "                       .reduceByKey(add)\n",
    "                \n",
    "#    r_rdd = r_rdd.filter(lambda x: x[1][0].split(\",\")[1]==\"1\")\n",
    "    \n",
    "    r_rdd = r_rdd.sortByKey().collect()\n",
    "    num_rec_ar = np.zeros((f_num, bins, 2, labels_num))\n",
    "    \n",
    "    for k,v in r_rdd:\n",
    "        k = list(map(int,k.split(\",\")))\n",
    "        num_rec_ar[k[0]][(k[1]-1)][k[2]][k[3]] = v\n",
    "    \n",
    "    return num_rec_ar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step - 6: Compute the Info-gain array of each case\n",
    "\n",
    "Computation of each possible attribute and corresponding bin number Information gain is done by the following function.\n",
    "\n",
    "We will use Gini Index to compute the Impurity of the node.\n",
    "\n",
    "Inputs:\n",
    "\n",
    "    num_rec_ar - a 4-d numpy array realizing the above table of shape (features, bins, 2, class)  obtained from get_num_rec\n",
    "    \n",
    "Outputs:\n",
    "\n",
    "    num_rec_frac - a numpy 4-d numpy array that sums up the accross the dimension 4 of the num_rec_ar \n",
    "    \n",
    "    current_node_imp - this a array that gives the number of records per class for the current node\n",
    "    \n",
    "    Infogain_ar - this array is the required infogain array to find the feature that has more Info-gain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_Infogain_ar(num_rec_ar):\n",
    "    \n",
    "    features, bins, dummy, labels = num_rec_ar.shape\n",
    "        \n",
    "    num_rec_ar_sum3 = np.sum(num_rec_ar, axis = 3, keepdims=True)\n",
    "        \n",
    "    num_rec_frac_ar = num_rec_ar/num_rec_ar_sum3\n",
    "    \n",
    "    num_rec_frac_ar[np.isnan(num_rec_frac_ar)] = 0\n",
    "    \n",
    "    # Gini Index\n",
    "\n",
    "    imp_ar = 1 - np.sum(num_rec_frac_ar**2,axis = 3, keepdims=True)\n",
    "    \n",
    "    ind = bins-1\n",
    "    \n",
    "    current_node_imp = imp_ar[0,ind,0,0]\n",
    "    \n",
    "    num_rec_ar_sum23 = np.sum(num_rec_ar_sum3, axis = 2,  keepdims=True)\n",
    "    \n",
    "    dum_np_ar = num_rec_ar_sum3[:,:-1,:,:]*imp_ar[:,:-1,:,:]/num_rec_ar_sum23[:,:-1,:,:]\n",
    "    \n",
    "    Infogain_ar = current_node_imp - np.sum(dum_np_ar, axis = 2)\n",
    "    \n",
    "    return num_rec_frac_ar, current_node_imp, Infogain_ar\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7-d: This will split the current node rdd into two child rdd's (left child and right child)\n",
    "\n",
    "This will split based on the feature and the bin number that is has been recognized to have the highest Info gain. \n",
    "\n",
    "The following modifications are important to the rdd after splitting:\n",
    "\n",
    "If the feature '0' and bin '5' has max Info gain then:\n",
    "\n",
    "        [['0','0,2,1,32', '1,5,1,32', '2,7,1,32'...],['1','0,3,1,32', '1,6,1,32', '2,7,1,32']]\n",
    "\n",
    "     => [['0','0,2,1,5', '1,5,1,32', '2,7,1,32'...],['1','0,3,1,5', '1,6,1,32', '2,7,1,32']]\n",
    "     \n",
    "     Max bin of feature '0' is change to 5\n",
    "     \n",
    "If the feature '1' and the bin is '4' has max Info gain:\n",
    "\n",
    "        [['0','0,2,1,32', '1,5,1,32', '2,7,1,32'...]...]\n",
    "\n",
    "     => [['0','0,2,1,32', '1,5,5,32', '2,7,1,32'...]...]\n",
    "     \n",
    "     Min bin of the feature '1' is change to 4+1 = '5' \n",
    "\n",
    "Inputs:\n",
    "\n",
    "    g_rdd - rdd at that node\n",
    "    \n",
    "    rec_dec - recent decision made based on Max Info-gain, it is a tuple containing the (feature, bin number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_lr_rdd(g_rdd, rec_dec):\n",
    "    \n",
    "    bc_dec_f = sc.broadcast(rec_dec[0])\n",
    "    bc_dec_bin = sc.broadcast(rec_dec[1]+1)\n",
    "    \n",
    "    \n",
    "    def get_lr_rdd_mapper(x):\n",
    "        \n",
    "        l_dec_f = bc_dec_f.value\n",
    "        l_dec_bin = bc_dec_bin.value\n",
    "        \n",
    "        f_mod = list(map(int,x[l_dec_f+1].split(\",\")))\n",
    "        \n",
    "        if f_mod[1]<=l_dec_bin:\n",
    "            \n",
    "            f_mod[3]=l_dec_bin\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            f_mod[2]=l_dec_bin+1\n",
    "           \n",
    "        x[l_dec_f+1]=str(f_mod).replace(\"[\",\"\").replace(\"]\",\"\").replace(\" \",\"\")\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    def get_l_filter(x):\n",
    "        \n",
    "        l_dec_f = bc_dec_f.value\n",
    "        l_dec_bin = bc_dec_bin.value\n",
    "        \n",
    "        f_mod = list(map(int,x[l_dec_f+1].split(\",\")))\n",
    "        \n",
    "        if f_mod[1]<=l_dec_bin:\n",
    "            \n",
    "            return True \n",
    "            \n",
    "        else:\n",
    "            \n",
    "            return False\n",
    "    \n",
    "    def get_r_filter(x):\n",
    "        \n",
    "        return not get_l_filter(x)\n",
    "        \n",
    "    \n",
    "    l_rdd, r_rdd = (g_rdd.filter(f) for f in (get_l_filter, get_r_filter)) \n",
    "\n",
    "    l_rdd = l_rdd.map(get_lr_rdd_mapper)\n",
    "    \n",
    "    r_rdd = r_rdd.map(get_lr_rdd_mapper)\n",
    "    \n",
    "    return l_rdd, r_rdd\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step - 7: Generate the tree:\n",
    "\n",
    "What this function does?\n",
    "\n",
    "Call the functions from step-1 to step-6, then do:\n",
    "\n",
    "    7a. After getting Info gain numpy array. Find the one which is the maximum value and make corresponding feature as a decision feature with bin*bin_width + min as the value based on the which it will proceed to the next node. \n",
    "\n",
    "    7b. Store this information in the tree_dic dictionary as [Node# : (feature, bin*bin_width, None, None)\n",
    "\n",
    "    7c. Store the nodes impurities a.k.a the number of recs per class on the left and right child from the table obatined from the get_num_rec() function as numpy array of shape (features, bins, 2, # of classes).  \n",
    "\n",
    "    7d. Split the rdd into two rdd's: \n",
    "\n",
    "        l_rdd - this is the rdd which contains all the rows that contain value of the feature selected above <= bin*bin_width + min.\n",
    "\n",
    "        r_rdd - this is the rdd which contains all the rows that contain value of the feature selected above > bin*bin_width + min.\n",
    "\n",
    "    7e. Save the above two rdds which will be given to get_num_rec() function in the next iteration to get the similar table as we got above. These rdd's are stored in the dictionary nodes_rdd[2*i+1: l_rdd, 2*i+2: r_rdd]\n",
    "\n",
    "    7f. Repeat the 7a - 7e on the next nodes rdd in nodes_rdd dictionary until you get the tree of desired depth.\n",
    "\n",
    "Inputs:\n",
    "\n",
    "    train_rdd - training data\n",
    "    \n",
    "    max_depth - depth of the tree\n",
    "    \n",
    "    total_col - total number of columns\n",
    "    \n",
    "    rem_col - columns that shouldn't be considered like ID column\n",
    "    \n",
    "    label_col - column in which class label is present\n",
    "    \n",
    "    bins - number of bins\n",
    "    \n",
    "Output:\n",
    "\n",
    "    tree_dic - decision tree in the form of an dictionary, where:\n",
    "                \n",
    "                {Node# : (feature_at_test, feature_value, None, None)}\n",
    "                \n",
    "    nodes_rec_frac - np_array obtained from the get_Infogain() function\n",
    "    \n",
    "    nodes_imp - number of records of each class at each node in the form of a dict as follows:\n",
    "    \n",
    "                {Node# : [records_of_class0, records_of_class1]}\n",
    "                \n",
    "    labels - labels dictionary of form :\n",
    "                \n",
    "                    {'B': 0, 'M': 1}\n",
    "                    \n",
    "    bin_width - bin width of each feature\n",
    "    \n",
    "    \n",
    "Tree is visualized as follows:\n",
    "\n",
    "    Node 0 : root node\n",
    "    \n",
    "    Node 1 : left child of root node\n",
    "    \n",
    "    Node 2 : right child of root node\n",
    "    \n",
    "    Node 3 : left child of (i-1)/2 here i=3 => parent is 2\n",
    "    \n",
    "    Node 4 : right child of (i-1)/2 here i=4 => parent is 2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_tree(train_rdd, max_depth, total_col, rem_col, label_col, bins):\n",
    "    \n",
    "    tree_dic = {}\n",
    "\n",
    "    nodes_rdd ={}\n",
    "    \n",
    "    nodes_imp = {}\n",
    "    \n",
    "    nodes_rec_frac = {}\n",
    "    \n",
    "    f_col = rem_col + label_col\n",
    "\n",
    "    k = len(rem_col)+len(label_col)\n",
    "    \n",
    "    f_num = total_col - k\n",
    "    \n",
    "    min_f, max_f = get_min_max(train_rdd, f_col, k)\n",
    "    \n",
    "    bin_width = get_bin_width(min_f, max_f, bins)\n",
    "    \n",
    "    labels = get_labels(train_rdd, label_col)\n",
    "    \n",
    "    clean_rdd = clean_data(train_rdd, rem_col, label_col, bin_width, labels, bins, min_f)\n",
    "     \n",
    "    nodes_rdd[0] = clean_rdd\n",
    "    \n",
    "    #i = 0\n",
    "    \n",
    "    #while max(tree_dic, key=tree_dic.get)==(2**(max_depth)-1):\n",
    "    \n",
    "    max_iter = (2**max_depth)-1\n",
    "\n",
    "    for i in range(0,max_iter): \n",
    "        \n",
    "        if i!=0 and 0 in nodes_rec_frac[i]:\n",
    "            \n",
    "            nodes_rec_frac[2*i+1] = nodes_rec_frac[i]\n",
    "            nodes_rec_frac[2*i+1] = nodes_rec_frac[i]\n",
    "            \n",
    "            nodes_rdd[2*i+1] = nodes_rdd[i]\n",
    "            nodes_rdd[2*i+2] = nodes_rdd[i]\n",
    "            \n",
    "            tree_dic[i] = None\n",
    "            \n",
    "            nodes_imp[i] = 0 \n",
    "            \n",
    "        else:    \n",
    "\n",
    "\n",
    "            num_rec_ar = get_num_rec(nodes_rdd[i], label_col, bins, f_num, len(labels))\n",
    "\n",
    "            num_rec_frac_ar, current_node_imp, Infogain_ar = get_Infogain_ar(num_rec_ar)\n",
    "\n",
    "        #     print(Infogain_ar.shape)\n",
    "\n",
    "        #     print(Infogain_ar[0])\n",
    "\n",
    "        #     print(current_node_imp)\n",
    "\n",
    "        #     print(num_rec_frac_ar.shape)\n",
    "\n",
    "        #     print(num_rec_frac_ar[0])\n",
    "\n",
    "        #     print(num_rec_ar[0])\n",
    "\n",
    "            dec_ind = np.where(Infogain_ar==np.nanmax(Infogain_ar))\n",
    "\n",
    "            dec_ind = list(a_i[0] for a_i in dec_ind)\n",
    "\n",
    "        #     print(dec_ind)\n",
    "\n",
    "            tree_dic[i] = (dec_ind[0], (dec_ind[1]+1)*bin_width[str(dec_ind[0])]+min_f[str(dec_ind[0])], None, None)\n",
    "\n",
    "            rec_t_dec = (dec_ind[0], dec_ind[1])\n",
    "\n",
    "            nodes_imp[i] = current_node_imp\n",
    "\n",
    "            if i==0:\n",
    "                nodes_rec_frac[i] = num_rec_ar[0,bins-1,0,:].astype(int).tolist()\n",
    "\n",
    "            nodes_rec_frac[2*i+1] = num_rec_ar[rec_t_dec[0], rec_t_dec[1],0,:].astype(int).tolist()\n",
    "\n",
    "            nodes_rec_frac[2*i+2] = num_rec_ar[rec_t_dec[0], rec_t_dec[1],1,:].astype(int).tolist()\n",
    "\n",
    "#             print(rec_t_dec)\n",
    "\n",
    "#             print(nodes_rec_frac)\n",
    "\n",
    "#             print(nodes_imp)\n",
    "\n",
    "    #        print(num_rec_ar[rec_t_dec[0],:,:,:])\n",
    "\n",
    "            l_rdd , r_rdd = get_lr_rdd(nodes_rdd[i], rec_t_dec)\n",
    "\n",
    "            nodes_rdd[2*i+1] = l_rdd\n",
    "\n",
    "            nodes_rdd[2*i+2] = r_rdd\n",
    "\n",
    "#             print(l_rdd.count())\n",
    "\n",
    "#             print(r_rdd.count())\n",
    "\n",
    "#             print(tree_dic)\n",
    "\n",
    "#         print(nodes_rec_frac)\n",
    "    \n",
    "    return tree_dic, nodes_rec_frac, nodes_imp, labels, bin_width\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling the get_tree function with appropriate Inputs\n",
    "\n",
    "The outputs of get_tree function is also printed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Varun\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n",
      "C:\\Users\\Varun\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree dictionary:\n",
      " {0: (22, 113.15687499999999, None, None), 1: (27, 0.1455, None, None), 2: (21, 20.2275, None, None), 3: (22, 106.88218749999999, None, None), 4: (21, 23.744999999999997, None, None), 5: (7, 0.0691625, None, None), 6: (20, 15.8359375, None, None)}\n",
      "\n",
      "\n",
      "nodes_rec_frac:\n",
      " {0: [281, 180], 1: [275, 29], 2: [6, 151], 3: [268, 9], 4: [7, 20], 5: [5, 6], 6: [1, 145], 7: [258, 4], 8: [10, 5], 9: [6, 1], 10: [1, 19], 11: [5, 0], 12: [0, 6], 13: [1, 0], 14: [0, 145]}\n",
      "\n",
      "\n",
      "nodes_imp:\n",
      " {0: 0.4760000188216693, 1: 0.17258916204986163, 2: 0.07351211002474733, 3: 0.06287062258077136, 4: 0.384087791495199, 5: 0.49586776859504145, 6: 0.013604803903171314}\n",
      "\n",
      "\n",
      "bin_width:\n",
      " {'0': 0.63871875, '1': 0.9240625, '2': 4.4721875, '3': 73.671875, '4': 0.0028771874999999995, '5': 0.010188125, '6': 0.0133375, '7': 0.0062875, '8': 0.005768750000000001, '9': 0.0014309375000000001, '10': 0.075990625, '11': 0.141340625, '12': 0.5591562499999999, '13': 16.7311875, '14': 0.0009192812500000001, '15': 0.004160875, '16': 0.012375, '17': 0.0016496875, '18': 0.002220875, '19': 0.0009045374999999999, '20': 0.8784375, '21': 1.1724999999999999, '22': 6.2746875, '23': 127.15, '24': 0.0047321875, '25': 0.0322096875, '26': 0.039125, '27': 0.00909375, '28': 0.013153125000000002, '29': 0.0047643749999999995}\n",
      "\n",
      "\n",
      "labels:\n",
      " {'B': 0, 'M': 1}\n"
     ]
    }
   ],
   "source": [
    "max_depth = 3\n",
    "\n",
    "total_col = 32\n",
    "\n",
    "# irrrelavant columns\n",
    "rem_col = [0]\n",
    "\n",
    "# label column\n",
    "label_col = [1]\n",
    "\n",
    "bins = 32\n",
    "\n",
    "k = len(rem_col)+len(label_col)\n",
    "\n",
    "\n",
    "train_rdd, test_rdd = raw_rdd.randomSplit([0.8, 0.2], seed = 43)\n",
    "\n",
    "tree_dic, nodes_rec_frac, nodes_imp, labels, bin_width = get_tree(train_rdd, max_depth, total_col, rem_col, label_col, bins)\n",
    "\n",
    "print(\"Tree dictionary:\\n\",tree_dic)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"nodes_rec_frac:\\n\",nodes_rec_frac)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"nodes_imp:\\n\",nodes_imp)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"bin_width:\\n\",bin_width)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print (\"labels:\\n\",labels)            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step - 8: Interpreting the tree \n",
    "\n",
    "Call this function to change the tree_dic to a interpretable format as shown below:\n",
    "\n",
    "    {Node # : (feature_at_test, value, if_feature_value<=value: this class, if_feature_value>value: this class )}\n",
    "\n",
    "Example:\n",
    "        \n",
    "    {..4: (21, 23.744999999999997, 'B', 'M')..}\n",
    "    \n",
    "    feature at test at node 4 is 21 and value is 23.7499.\n",
    "    \n",
    "    If the test record feature 21 has value =< 23.7499 then the class of the record is 'B'.\n",
    "    \n",
    "    Else the test record feature 21 has value > 23.7499 then the class of the record is 'M'.\n",
    "    \n",
    "Inputs:\n",
    "\n",
    "    max_depth - depth of the tree\n",
    "    \n",
    "    tree_dic - tree_dic form get_tree() function\n",
    "    \n",
    "    nodes_rec_frac - obtained from the get_Infogain() function\n",
    "    \n",
    "    labels - obtained form get_tree() function\n",
    "    \n",
    "Outputs:\n",
    "\n",
    "    tree_dic - modified tree_dic as described above\n",
    "    \n",
    "    leaf_nodes - leaf_nodes class dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leaf nodes dictionary:\n",
      " {7: 0, 8: 0, 9: 0, 10: 1, 11: 0, 12: 1, 13: 0, 14: 1}\n",
      "Tree dictionary:\n",
      " {0: (22, 113.15687499999999, None, None), 1: (27, 0.1455, 'B', None), 2: (21, 20.2275, None, None), 3: (22, 106.88218749999999, None, None), 4: (21, 23.744999999999997, 'B', 'M'), 5: (7, 0.0691625, 'B', 'M'), 6: (20, 15.8359375, 'B', 'M')}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def interpret_tree(max_depth, tree_dic, nodes_rec_frac, labels):\n",
    "    \n",
    "    leaf_labels = {}\n",
    "    \n",
    "    check = 0\n",
    "    \n",
    "    inv_labels = {v:k for k,v in labels.items()}\n",
    "    \n",
    "    for i in range(2*max_depth+1, (2**(max_depth+1))-1):\n",
    "        \n",
    "            # Selecting leaf nodes class based on max num of records at the leaf nodes\n",
    "            \n",
    "            leaf_labels[i] = nodes_rec_frac[i].index(max(nodes_rec_frac[i]))  \n",
    "            \n",
    "    for i in range(2*max_depth+1, (2**(max_depth+1))-1,2):\n",
    "        \n",
    "        l_label = inv_labels[leaf_labels[i]]\n",
    "        \n",
    "        r_label = inv_labels[leaf_labels[i+1]]\n",
    "        \n",
    "        if leaf_labels[i] == leaf_labels[i+1]:\n",
    "            \n",
    "            father_node = int((i-1)/2)\n",
    "            \n",
    "            grandfather_node = int((father_node-1)/2)\n",
    "            \n",
    "            if father_node%2!=0:\n",
    "                \n",
    "                tree_dic[grandfather_node] = (tree_dic[grandfather_node][0],tree_dic[grandfather_node][1],\\\n",
    "                                           l_label,tree_dic[grandfather_node][3])\n",
    "            else:\n",
    "                \n",
    "                tree_dic[grandfather_node] = (tree_dic[grandfather_node][0],tree_dic[grandfather_node][1],\\\n",
    "                                           tree_dic[grandfather_node][2],r_label)\n",
    "                \n",
    "        else:\n",
    "\n",
    "                father_node = int((i-1)/2)\n",
    "            \n",
    "                tree_dic[father_node] = (tree_dic[father_node][0],tree_dic[father_node][1],\\\n",
    "                                           l_label,tree_dic[father_node][3])\n",
    "                \n",
    "                tree_dic[father_node] = (tree_dic[father_node][0],tree_dic[father_node][1],\\\n",
    "                                           tree_dic[father_node][2],r_label)\n",
    "\n",
    "            \n",
    "            \n",
    "    return leaf_labels, tree_dic\n",
    "\n",
    "leaf_labels, tree_dic = interpret_tree(max_depth, tree_dic, nodes_rec_frac, labels)\n",
    "\n",
    "print(\"leaf nodes dictionary:\\n\",leaf_labels)\n",
    "\n",
    "print( \"Tree dictionary:\\n\",tree_dic)\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step - 9: Prediction function\n",
    "\n",
    "This function is used to predict the labels of any given row.\n",
    "\n",
    "Inputs:\n",
    "\n",
    "    tree_dic - the modified tree_dic\n",
    "    \n",
    "    test_rdd - rdd/data upon which it should be tested\n",
    "    \n",
    "    max_depth - max depth of the tree\n",
    "    \n",
    "    k - number of irrelevant columns other than features like ID and class\n",
    "    \n",
    "    label_col - column in which label is present\n",
    "    \n",
    "Outputs:\n",
    "\n",
    "    p_test_rdd - rdd with predicted class is added to class column as follows:\n",
    "    \n",
    "        ['ID', 'M,M',...]\n",
    "        \n",
    "        where first 'M' is the actual label and second 'M' is the predicted label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['84300903', 'M,M', '19.69', '21.25', '130', '1203', '0.1096', '0.1599', '0.1974', '0.1279', '0.2069', '0.05999', '0.7456', '0.7869', '4.585', '94.03', '0.00615', '0.04006', '0.03832', '0.02058', '0.0225', '0.004571', '23.57', '25.53', '152.5', '1709', '0.1444', '0.4245', '0.4504', '0.243', '0.3613', '0.08758']\n"
     ]
    }
   ],
   "source": [
    "def predict(tree_dic, test_rdd, max_depth, k, label_col):\n",
    "    \n",
    "    bc_max_depth = sc.broadcast(max_depth)    \n",
    "    bc_tree_dic = sc.broadcast(tree_dic)\n",
    "    bc_k = sc.broadcast(k)\n",
    "    bc_label_col = sc.broadcast(label_col)\n",
    "    \n",
    "    def predict_mapper(x):\n",
    "        \n",
    "        x = x.split(\",\")\n",
    "        l_max_depth = bc_max_depth.value\n",
    "        l_tree_dic = bc_tree_dic.value\n",
    "        l_k = bc_k.value\n",
    "        l_label_col = bc_label_col.value\n",
    "        i = 0\n",
    "        \n",
    "        while(i<2**(l_max_depth+1)-1):\n",
    "            \n",
    "            feature, val, l_label, r_label = tree_dic[i]\n",
    "            \n",
    "            if float(x[feature+l_k]) <= val:\n",
    "                \n",
    "                if l_label == None:\n",
    "                    \n",
    "                    i = 2*i+1\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    predicted_label = l_label\n",
    "                    \n",
    "                    break\n",
    "                    \n",
    "            else:\n",
    "                \n",
    "                if r_label == None:\n",
    "                    \n",
    "                    i = 2*i+2\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    predicted_label = r_label\n",
    "                    \n",
    "                    break\n",
    "                    \n",
    "        x[l_label_col] = x[l_label_col]+\",\"+predicted_label \n",
    "        \n",
    "        return x\n",
    "    \n",
    "    p_test_rdd = test_rdd.map(predict_mapper)\n",
    "    \n",
    "    return p_test_rdd\n",
    "    \n",
    "    \n",
    "p_test_rdd = predict(tree_dic, test_rdd, max_depth, k, label_col[0])\n",
    "\n",
    "p_train_rdd = predict(tree_dic, train_rdd, max_depth, k, label_col[0])\n",
    "\n",
    "print(p_test_rdd.first())\n",
    "                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step - 10 : Computing confusion matrix\n",
    "\n",
    "This computation is made easier by adding the predicted class label to the column class as discussed above. Now Mapper just throws that column and reducer will add by key to produce the confusion matrix as shown in the example.\n",
    "\n",
    "Inputs:\n",
    "\n",
    "    p_test_rdd - output from the predict()\n",
    "    \n",
    "    label_col - label column \n",
    "    \n",
    "Output:\n",
    "\n",
    "    confusion_mat_rdd - confusion matrix in the form of rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data confusion matrix: [('M,M', 28), ('M,B', 4), ('B,B', 72), ('B,M', 4)]\n",
      "Train data confusion matrix: [('M,M', 170), ('M,B', 10), ('B,B', 280), ('B,M', 1)]\n"
     ]
    }
   ],
   "source": [
    "def confusion_mat(p_test_rdd, label_col):\n",
    "    \n",
    "    bc_label_col = sc.broadcast(label_col)\n",
    "    \n",
    "    def confusion_mat_mapper(x):\n",
    "        \n",
    "        l_label_col = bc_label_col.value\n",
    "        \n",
    "        return(x[l_label_col],1)\n",
    "    \n",
    "    confusion_mat_rdd = p_test_rdd.map(confusion_mat_mapper)\\\n",
    "                                  .reduceByKey(add)\\\n",
    "                                  .collect()\n",
    "    \n",
    "    return confusion_mat_rdd\n",
    "\n",
    "confusion_mat_rdd_test = confusion_mat(p_test_rdd, label_col[0])\n",
    "\n",
    "confusion_mat_rdd_train = confusion_mat(p_train_rdd, label_col[0])\n",
    "\n",
    "print(\"Test data confusion matrix:\", confusion_mat_rdd_test)\n",
    "\n",
    "print(\"Train data confusion matrix:\", confusion_mat_rdd_train)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions:\n",
    "\n",
    "The validation is assumed to be random sampling. It did yield good results as seen from the confusion matrix above:\n",
    "    \n",
    "    The key's first letter indicates the actual class and the next letter is the predicted class\n",
    "    \n",
    "    The value is the number of records \n",
    "\n",
    "Upon comparison with the 4 A this is little low on performance but from the above we can see that the results are satisfactory.\n",
    "\n",
    "**What an exciting project!!!**\n",
    "\n",
    "                                                                                                    Author:\n",
    "                                                                                                    \n",
    "                                                                                                    Varun Raj Rayabarapu\n",
    "                                                                                                    University of Cincinnati"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
