{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment - 4 A Solution\n",
    "\n",
    "Use the MLLib API of Spark to construct a decision tree for the Breast Cancer Diagnostic data (we call it dataset1), available from the UC-Irvine ML repository. Select appropriate parameters to generate only a 3-level deep decision tree. Submit the following:\n",
    "\n",
    "a.\tYour program code.\n",
    "\n",
    "b.\tThe choice of parameters and attribute selection metric (Gini index, info gain, etc.) used.\n",
    "    \n",
    "    Impurity Measur: Gini Index\n",
    "    \n",
    "    Max depth of the tree: 3\n",
    "    \n",
    "    Max Bins of the continuous data: [10, 20, 32, 40, 50]\n",
    "\n",
    "c.\tAny assumptions made.\n",
    "\n",
    "    The one which has more Area under the ROC (AUROC) curve is the best model for our application.\n",
    "    \n",
    "    While performing K-fold Cross-validation the value of k is taken as 3.\n",
    "\n",
    "d.\tValidation and Train/Test Strategy used.\n",
    "    \n",
    "    Firstly, the entire data is split into train and test. Then, K-fold Cross-validation is performed on train to get model that will not overfit and more generalized. Finally, the model is tested against test data, and the performance metrics are also reported.\n",
    "\n",
    "e.\tDecision tree Obtained.\n",
    "\n",
    "f.\tPerformance shown by the confusion matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a SparkSession\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('DT_BC').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>_c1</th>\n",
       "      <th>_c2</th>\n",
       "      <th>_c3</th>\n",
       "      <th>_c4</th>\n",
       "      <th>_c5</th>\n",
       "      <th>_c6</th>\n",
       "      <th>_c7</th>\n",
       "      <th>_c8</th>\n",
       "      <th>_c9</th>\n",
       "      <th>...</th>\n",
       "      <th>_c22</th>\n",
       "      <th>_c23</th>\n",
       "      <th>_c24</th>\n",
       "      <th>_c25</th>\n",
       "      <th>_c26</th>\n",
       "      <th>_c27</th>\n",
       "      <th>_c28</th>\n",
       "      <th>_c29</th>\n",
       "      <th>_c30</th>\n",
       "      <th>_c31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.1184</td>\n",
       "      <td>0.2776</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.1471</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.1189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      _c0 _c1    _c2    _c3    _c4   _c5     _c6     _c7     _c8     _c9  \\\n",
       "0  842302   M  17.99  10.38  122.8  1001  0.1184  0.2776  0.3001  0.1471   \n",
       "\n",
       "    ...     _c22   _c23   _c24  _c25    _c26    _c27    _c28    _c29    _c30  \\\n",
       "0   ...    25.38  17.33  184.6  2019  0.1622  0.6656  0.7119  0.2654  0.4601   \n",
       "\n",
       "     _c31  \n",
       "0  0.1189  \n",
       "\n",
       "[1 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the csv data to a dataframe \n",
    "\n",
    "df = spark.read.csv('wdbc.csv')\n",
    "\n",
    "# Top 1 column of the dataframe\n",
    "\n",
    "df.limit(1).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      " |-- _c10: string (nullable = true)\n",
      " |-- _c11: string (nullable = true)\n",
      " |-- _c12: string (nullable = true)\n",
      " |-- _c13: string (nullable = true)\n",
      " |-- _c14: string (nullable = true)\n",
      " |-- _c15: string (nullable = true)\n",
      " |-- _c16: string (nullable = true)\n",
      " |-- _c17: string (nullable = true)\n",
      " |-- _c18: string (nullable = true)\n",
      " |-- _c19: string (nullable = true)\n",
      " |-- _c20: string (nullable = true)\n",
      " |-- _c21: string (nullable = true)\n",
      " |-- _c22: string (nullable = true)\n",
      " |-- _c23: string (nullable = true)\n",
      " |-- _c24: string (nullable = true)\n",
      " |-- _c25: string (nullable = true)\n",
      " |-- _c26: string (nullable = true)\n",
      " |-- _c27: string (nullable = true)\n",
      " |-- _c28: string (nullable = true)\n",
      " |-- _c29: string (nullable = true)\n",
      " |-- _c30: string (nullable = true)\n",
      " |-- _c31: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print schema of the datafame\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of rows\n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>_c1</th>\n",
       "      <th>_cc2</th>\n",
       "      <th>_cc3</th>\n",
       "      <th>_cc4</th>\n",
       "      <th>_cc5</th>\n",
       "      <th>_cc6</th>\n",
       "      <th>_cc7</th>\n",
       "      <th>_cc8</th>\n",
       "      <th>_cc9</th>\n",
       "      <th>...</th>\n",
       "      <th>_cc22</th>\n",
       "      <th>_cc23</th>\n",
       "      <th>_cc24</th>\n",
       "      <th>_cc25</th>\n",
       "      <th>_cc26</th>\n",
       "      <th>_cc27</th>\n",
       "      <th>_cc28</th>\n",
       "      <th>_cc29</th>\n",
       "      <th>_cc30</th>\n",
       "      <th>_cc31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.1184</td>\n",
       "      <td>0.2776</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.1471</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.1189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      _c0 _c1   _cc2   _cc3   _cc4    _cc5    _cc6    _cc7    _cc8    _cc9  \\\n",
       "0  842302   M  17.99  10.38  122.8  1001.0  0.1184  0.2776  0.3001  0.1471   \n",
       "\n",
       "    ...    _cc22  _cc23  _cc24   _cc25   _cc26   _cc27   _cc28   _cc29  \\\n",
       "0   ...    25.38  17.33  184.6  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "\n",
       "    _cc30   _cc31  \n",
       "0  0.4601  0.1189  \n",
       "\n",
       "[1 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to change the column type of the features to Double as all are read as string  \n",
    "# Then we drop all the string type columns \n",
    "\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "for i in range(2,len(df.columns)):\n",
    "    df = df.withColumn(\"_cc\"+str(i),df[\"_c\"+str(i)].cast(DoubleType()))\n",
    "    df = df.drop('_c'+str(i))\n",
    "        \n",
    "df.limit(1).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(min(_cc31)=0.05504)\n"
     ]
    }
   ],
   "source": [
    "row1 = df.agg({\"_cc31\": \"min\"}).collect()[0]\n",
    "\n",
    "print(row1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _cc2: double (nullable = true)\n",
      " |-- _cc3: double (nullable = true)\n",
      " |-- _cc4: double (nullable = true)\n",
      " |-- _cc5: double (nullable = true)\n",
      " |-- _cc6: double (nullable = true)\n",
      " |-- _cc7: double (nullable = true)\n",
      " |-- _cc8: double (nullable = true)\n",
      " |-- _cc9: double (nullable = true)\n",
      " |-- _cc10: double (nullable = true)\n",
      " |-- _cc11: double (nullable = true)\n",
      " |-- _cc12: double (nullable = true)\n",
      " |-- _cc13: double (nullable = true)\n",
      " |-- _cc14: double (nullable = true)\n",
      " |-- _cc15: double (nullable = true)\n",
      " |-- _cc16: double (nullable = true)\n",
      " |-- _cc17: double (nullable = true)\n",
      " |-- _cc18: double (nullable = true)\n",
      " |-- _cc19: double (nullable = true)\n",
      " |-- _cc20: double (nullable = true)\n",
      " |-- _cc21: double (nullable = true)\n",
      " |-- _cc22: double (nullable = true)\n",
      " |-- _cc23: double (nullable = true)\n",
      " |-- _cc24: double (nullable = true)\n",
      " |-- _cc25: double (nullable = true)\n",
      " |-- _cc26: double (nullable = true)\n",
      " |-- _cc27: double (nullable = true)\n",
      " |-- _cc28: double (nullable = true)\n",
      " |-- _cc29: double (nullable = true)\n",
      " |-- _cc30: double (nullable = true)\n",
      " |-- _cc31: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the schema of the dataframe\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c1</th>\n",
       "      <th>_cc2</th>\n",
       "      <th>_cc3</th>\n",
       "      <th>_cc4</th>\n",
       "      <th>_cc5</th>\n",
       "      <th>_cc6</th>\n",
       "      <th>_cc7</th>\n",
       "      <th>_cc8</th>\n",
       "      <th>_cc9</th>\n",
       "      <th>_cc10</th>\n",
       "      <th>...</th>\n",
       "      <th>_cc22</th>\n",
       "      <th>_cc23</th>\n",
       "      <th>_cc24</th>\n",
       "      <th>_cc25</th>\n",
       "      <th>_cc26</th>\n",
       "      <th>_cc27</th>\n",
       "      <th>_cc28</th>\n",
       "      <th>_cc29</th>\n",
       "      <th>_cc30</th>\n",
       "      <th>_cc31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.1184</td>\n",
       "      <td>0.2776</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.1471</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.1189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  _c1   _cc2   _cc3   _cc4    _cc5    _cc6    _cc7    _cc8    _cc9   _cc10  \\\n",
       "0   M  17.99  10.38  122.8  1001.0  0.1184  0.2776  0.3001  0.1471  0.2419   \n",
       "\n",
       "    ...    _cc22  _cc23  _cc24   _cc25   _cc26   _cc27   _cc28   _cc29  \\\n",
       "0   ...    25.38  17.33  184.6  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "\n",
       "    _cc30   _cc31  \n",
       "0  0.4601  0.1189  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the first column as well since it is the id of each row which is not a feature\n",
    "\n",
    "df = df.drop('_c0')\n",
    "\n",
    "df.limit(1).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will then use StringIndexer to encode the label as Malignant(M):1 and Benign(B):0 \n",
    "# We will also use VectorAssembler to create a vector of features which will be given to the DecisionTreeClassifier\n",
    "# The above two stages are combined to form a Pipeline\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "\n",
    "label_stringIdx = StringIndexer(inputCol = '_c1', outputCol = 'label')\n",
    "\n",
    "assemblerInputs = [\"_cc\"+str(i) for i in range(2,len(df.columns))]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "\n",
    "stages=[label_stringIdx, assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _cc2: double (nullable = true)\n",
      " |-- _cc3: double (nullable = true)\n",
      " |-- _cc4: double (nullable = true)\n",
      " |-- _cc5: double (nullable = true)\n",
      " |-- _cc6: double (nullable = true)\n",
      " |-- _cc7: double (nullable = true)\n",
      " |-- _cc8: double (nullable = true)\n",
      " |-- _cc9: double (nullable = true)\n",
      " |-- _cc10: double (nullable = true)\n",
      " |-- _cc11: double (nullable = true)\n",
      " |-- _cc12: double (nullable = true)\n",
      " |-- _cc13: double (nullable = true)\n",
      " |-- _cc14: double (nullable = true)\n",
      " |-- _cc15: double (nullable = true)\n",
      " |-- _cc16: double (nullable = true)\n",
      " |-- _cc17: double (nullable = true)\n",
      " |-- _cc18: double (nullable = true)\n",
      " |-- _cc19: double (nullable = true)\n",
      " |-- _cc20: double (nullable = true)\n",
      " |-- _cc21: double (nullable = true)\n",
      " |-- _cc22: double (nullable = true)\n",
      " |-- _cc23: double (nullable = true)\n",
      " |-- _cc24: double (nullable = true)\n",
      " |-- _cc25: double (nullable = true)\n",
      " |-- _cc26: double (nullable = true)\n",
      " |-- _cc27: double (nullable = true)\n",
      " |-- _cc28: double (nullable = true)\n",
      " |-- _cc29: double (nullable = true)\n",
      " |-- _cc30: double (nullable = true)\n",
      " |-- _cc31: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a Pipeline and Pass the dataframe into the pipeline to transform as required to the DecisionTreeClassifier\n",
    "\n",
    "cols = df.columns\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=stages)\n",
    "\n",
    "pipelineModel = pipeline.fit(df)\n",
    "\n",
    "df = pipelineModel.transform(df)\n",
    "\n",
    "n_cols = ['label', 'features']+cols\n",
    "\n",
    "df = df.select(n_cols)\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label=1.0, features=DenseVector([17.99, 10.38, 122.8, 1001.0, 0.1184, 0.2776, 0.3001, 0.1471, 0.2419, 0.0787, 1.095, 0.9053, 8.589, 153.4, 0.0064, 0.049, 0.0537, 0.0159, 0.03, 0.0062, 25.38, 17.33, 184.6, 2019.0, 0.1622, 0.6656, 0.7119, 0.2654, 0.4601]), _c1='M', _cc2=17.99, _cc3=10.38, _cc4=122.8, _cc5=1001.0, _cc6=0.1184, _cc7=0.2776, _cc8=0.3001, _cc9=0.1471, _cc10=0.2419, _cc11=0.07871, _cc12=1.095, _cc13=0.9053, _cc14=8.589, _cc15=153.4, _cc16=0.006399, _cc17=0.04904, _cc18=0.05373, _cc19=0.01587, _cc20=0.03003, _cc21=0.006193, _cc22=25.38, _cc23=17.33, _cc24=184.6, _cc25=2019.0, _cc26=0.1622, _cc27=0.6656, _cc28=0.7119, _cc29=0.2654, _cc30=0.4601, _cc31=0.1189)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top row of the dataframe\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "      <th>_c1</th>\n",
       "      <th>_cc2</th>\n",
       "      <th>_cc3</th>\n",
       "      <th>_cc4</th>\n",
       "      <th>_cc5</th>\n",
       "      <th>_cc6</th>\n",
       "      <th>_cc7</th>\n",
       "      <th>_cc8</th>\n",
       "      <th>...</th>\n",
       "      <th>_cc22</th>\n",
       "      <th>_cc23</th>\n",
       "      <th>_cc24</th>\n",
       "      <th>_cc25</th>\n",
       "      <th>_cc26</th>\n",
       "      <th>_cc27</th>\n",
       "      <th>_cc28</th>\n",
       "      <th>_cc29</th>\n",
       "      <th>_cc30</th>\n",
       "      <th>_cc31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[6.981, 13.43, 43.79, 143.5, 0.117, 0.07568, 0...</td>\n",
       "      <td>B</td>\n",
       "      <td>6.981</td>\n",
       "      <td>13.43</td>\n",
       "      <td>43.79</td>\n",
       "      <td>143.5</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.07568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.93</td>\n",
       "      <td>19.54</td>\n",
       "      <td>50.41</td>\n",
       "      <td>185.2</td>\n",
       "      <td>0.1584</td>\n",
       "      <td>0.1202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2932</td>\n",
       "      <td>0.09382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           features _c1   _cc2   _cc3  \\\n",
       "0    0.0  [6.981, 13.43, 43.79, 143.5, 0.117, 0.07568, 0...   B  6.981  13.43   \n",
       "\n",
       "    _cc4   _cc5   _cc6     _cc7  _cc8   ...     _cc22  _cc23  _cc24  _cc25  \\\n",
       "0  43.79  143.5  0.117  0.07568   0.0   ...      7.93  19.54  50.41  185.2   \n",
       "\n",
       "    _cc26   _cc27  _cc28  _cc29   _cc30    _cc31  \n",
       "0  0.1584  0.1202    0.0    0.0  0.2932  0.09382  \n",
       "\n",
       "[1 rows x 33 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spliting the data into train and split\n",
    "\n",
    "train, test = df.randomSplit([0.7, 0.3], seed = 2018)\n",
    "\n",
    "# Print the top of the train and test dataframe\n",
    "\n",
    "train.limit(1).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "      <th>_c1</th>\n",
       "      <th>_cc2</th>\n",
       "      <th>_cc3</th>\n",
       "      <th>_cc4</th>\n",
       "      <th>_cc5</th>\n",
       "      <th>_cc6</th>\n",
       "      <th>_cc7</th>\n",
       "      <th>_cc8</th>\n",
       "      <th>...</th>\n",
       "      <th>_cc22</th>\n",
       "      <th>_cc23</th>\n",
       "      <th>_cc24</th>\n",
       "      <th>_cc25</th>\n",
       "      <th>_cc26</th>\n",
       "      <th>_cc27</th>\n",
       "      <th>_cc28</th>\n",
       "      <th>_cc29</th>\n",
       "      <th>_cc30</th>\n",
       "      <th>_cc31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[7.76, 24.54, 47.92, 181.0, 0.05263, 0.04362, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           features _c1  _cc2   _cc3  \\\n",
       "0    0.0  [7.76, 24.54, 47.92, 181.0, 0.05263, 0.04362, ...   B  7.76  24.54   \n",
       "\n",
       "    _cc4   _cc5     _cc6     _cc7  _cc8   ...     _cc22  _cc23  _cc24  _cc25  \\\n",
       "0  47.92  181.0  0.05263  0.04362   0.0   ...     9.456  30.37  59.16  268.6   \n",
       "\n",
       "     _cc26    _cc27  _cc28  _cc29   _cc30    _cc31  \n",
       "0  0.08996  0.06444    0.0    0.0  0.2871  0.07039  \n",
       "\n",
       "[1 rows x 33 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.limit(1).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use CrossValidation to to tune the maxBins size to get a best model\n",
    "# The evaluator to this will be the Area under the ROC curve(AUROC)\n",
    "\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator() # The evalutor is AUROC by default\n",
    "\n",
    "# Impurity is Gini by default\n",
    "\n",
    "dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'label', maxDepth = 3) \n",
    "\n",
    "# We will add the maxBin parameters based which the CrossValidation will go  \n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(dt.maxBins, [10, 20, 32]) \\\n",
    "    .build()\n",
    "\n",
    "cv = CrossValidator(estimator=dt, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=3)\n",
    "\n",
    "# Fit the train data to get the model\n",
    "\n",
    "cvModel = cv.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_44388b404477) of depth 3 with 13 nodes\n",
      "  If (feature 22 <= 113.15)\n",
      "   If (feature 27 <= 0.1572)\n",
      "    Predict: 0.0\n",
      "   Else (feature 27 > 0.1572)\n",
      "    If (feature 21 <= 23.59)\n",
      "     Predict: 0.0\n",
      "    Else (feature 21 > 23.59)\n",
      "     Predict: 1.0\n",
      "  Else (feature 22 > 113.15)\n",
      "   If (feature 23 <= 827.85)\n",
      "    If (feature 1 <= 20.155)\n",
      "     Predict: 0.0\n",
      "    Else (feature 1 > 20.155)\n",
      "     Predict: 1.0\n",
      "   Else (feature 23 > 827.85)\n",
      "    If (feature 26 <= 0.19190000000000002)\n",
      "     Predict: 0.0\n",
      "    Else (feature 26 > 0.19190000000000002)\n",
      "     Predict: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pull out the best model\n",
    "\n",
    "BestModel = cvModel.bestModel\n",
    "print(BestModel.toDebugString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cacheNodeIds: If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees. (default: False)\n",
      "checkpointInterval: set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext (default: 10)\n",
      "featuresCol: features column name (default: features, current: features)\n",
      "impurity: Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini (default: gini)\n",
      "labelCol: label column name (default: label, current: label)\n",
      "maxBins: Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature. (default: 32, current: 32)\n",
      "maxDepth: Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. (default: 5, current: 3)\n",
      "maxMemoryInMB: Maximum memory in MB allocated to histogram aggregation. (default: 256)\n",
      "minInfoGain: Minimum information gain for a split to be considered at a tree node. (default: 0.0)\n",
      "minInstancesPerNode: Minimum number of instances each child must have after split.  If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1. (default: 1)\n",
      "predictionCol: prediction column name (default: prediction)\n",
      "probabilityCol: Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities (default: probability)\n",
      "rawPredictionCol: raw prediction (a.k.a. confidence) column name (default: rawPrediction)\n",
      "seed: random seed (default: 956191873026065186)\n",
      "thresholds: Thresholds in multi-class classification to adjust the probability of predicting each class. Array must have length equal to the number of classes, with values > 0 excepting that at most one value may be 0. The class with largest value p/t is predicted, where p is the original probability of that class and t is the class's threshold (undefined)\n"
     ]
    }
   ],
   "source": [
    "# What are the Parameters of the best model\n",
    "\n",
    "print(BestModel.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of 1:Malignant\t 0.8767123287671232\n",
      "Precision of 0:Benign\t\t 0.9603960396039604\n",
      "Recall of 1:Malignant\t\t 0.9411764705882353\n",
      "Recall of 0:Benign\t\t 0.9150943396226415\n",
      "F-1 Score\t\t\t 0.9252873563218391\n",
      "Confusion Matrix\n",
      " [[97.  9.]\n",
      " [ 4. 64.]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluation of the model on the test data and the following are computed:\n",
    "# 1. Precision of 1\n",
    "# 2. Precision of 0\n",
    "# 3. Recall of 1\n",
    "# 4. Recall of 0\n",
    "# 5. F-1 Score\n",
    "# 6. Confusion Matrix\n",
    "\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "def getPredictionsLabels(model, test_data):\n",
    "    predictions = cvModel.transform(test_data)\n",
    "    predictions_n = predictions[\"label\", \"prediction\"]\n",
    "    predictionsAndLabels = predictions_n.rdd.map(tuple)\n",
    "    return  predictionsAndLabels\n",
    "\n",
    "def printMetrics(predictions_and_labels):\n",
    "    metrics = MulticlassMetrics(predictions_and_labels)\n",
    "    print ('Precision of 1:Malignant\\t', metrics.precision(1))\n",
    "    print ('Precision of 0:Benign\\t\\t', metrics.precision(0))\n",
    "    print ('Recall of 1:Malignant\\t\\t', metrics.recall(1))\n",
    "    print ('Recall of 0:Benign\\t\\t', metrics.recall(0))\n",
    "    print ('F-1 Score\\t\\t\\t', metrics.fMeasure())\n",
    "    print ('Confusion Matrix\\n', metrics.confusionMatrix().toArray())\n",
    "\n",
    "predictions_and_labels = getPredictionsLabels(cvModel, test)\n",
    "\n",
    "printMetrics(predictions_and_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                                                    Author:\n",
    "                                                                                                        Varun Raj Rayabarapu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
